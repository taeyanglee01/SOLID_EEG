{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dc9471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmdb\n",
    "import datetime\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "import scipy.io\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from einops import rearrange\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d96eafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(array):\n",
    "    return torch.from_numpy(array).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a341e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    print(f'set seed {seed} is done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3389d8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "KeyT = Union[str, bytes, bytearray]\n",
    "\n",
    "_KEY_RE = re.compile(\n",
    "   r\"^S(?P<sub_id>\\d{3})R\\d{2}-\\d+$\"\n",
    ")\n",
    "\n",
    "# S012R04-21\n",
    "\n",
    "def _decode_key(k: KeyT) -> str:\n",
    "    if isinstance(k, (bytes, bytearray)):\n",
    "        return k.decode(\"utf-8\", errors=\"ignore\")\n",
    "    return k\n",
    "\n",
    "def _extract_sub_id(k: KeyT) -> str:\n",
    "    s = _decode_key(k)\n",
    "    m = _KEY_RE.match(s)\n",
    "    if m is None:\n",
    "        raise ValueError(f\"Key does not match expected patterns: {s}\")\n",
    "    return m.group(\"sub_id\")\n",
    "\n",
    "\n",
    "def train_test_split_by_fold_num(\n",
    "    fold_num: int,\n",
    "    lmdb_keys: List[KeyT],\n",
    "    maxFold: int,\n",
    "    split_by_sub: bool = True,\n",
    "    seed: int = 41\n",
    ") -> Tuple[List[KeyT], List[KeyT]]:\n",
    "    \"\"\"\n",
    "    True k-fold cross-validation split.\n",
    "\n",
    "    Args:\n",
    "        fold_num: test fold index (0 <= fold_num < maxFold)\n",
    "        lmdb_keys: LMDB key list\n",
    "        maxFold: total number of folds (k)\n",
    "        split_by_sub: True → subject-wise k-fold, False → key-wise k-fold\n",
    "\n",
    "    Returns:\n",
    "        train_key_list, test_key_list\n",
    "    \"\"\"\n",
    "    if maxFold < 2:\n",
    "        raise ValueError(\"maxFold must be >= 2.\")\n",
    "    if fold_num < 0 or fold_num >= maxFold:\n",
    "        raise ValueError(f\"fold_num must be in [0, {maxFold-1}]\")\n",
    "\n",
    "    keys = list(lmdb_keys)\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    if split_by_sub:\n",
    "        # -------- subject-wise k-fold --------\n",
    "        sub_to_keys = defaultdict(list)\n",
    "        invalid = []\n",
    "\n",
    "        for k in keys:\n",
    "            try:\n",
    "                sid = _extract_sub_id(k)\n",
    "                sub_to_keys[sid].append(k)\n",
    "            except ValueError:\n",
    "                invalid.append(_decode_key(k))\n",
    "\n",
    "        if invalid:\n",
    "            ex = \"\\n\".join(invalid[:10])\n",
    "            raise ValueError(\n",
    "                f\"Found {len(invalid)} invalid keys. Examples:\\n{ex}\"\n",
    "            )\n",
    "\n",
    "        subjects = np.array(list(sub_to_keys.keys()), dtype=object)\n",
    "        rng.shuffle(subjects)\n",
    "\n",
    "        subj_folds = np.array_split(subjects, maxFold)\n",
    "        test_subjects = set(subj_folds[fold_num].tolist())\n",
    "\n",
    "        train_keys, test_keys = [], []\n",
    "        for sid, ks in sub_to_keys.items():\n",
    "            (test_keys if sid in test_subjects else train_keys).extend(ks)\n",
    "\n",
    "        return train_keys, test_keys\n",
    "\n",
    "    else:\n",
    "        # -------- key-wise k-fold --------\n",
    "        idx = np.arange(len(keys))\n",
    "        rng.shuffle(idx)\n",
    "\n",
    "        folds = np.array_split(idx, maxFold)\n",
    "        test_idx = set(folds[fold_num].tolist())\n",
    "\n",
    "        train_keys = [keys[i] for i in idx if i not in test_idx]\n",
    "        test_keys  = [keys[i] for i in idx if i in test_idx]\n",
    "\n",
    "        return train_keys, test_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d4bec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "LMDB = '/pscratch/sd/t/tylee/Dataset/PhysioNet_200Hz_for_SOLID'\n",
    "\n",
    "DB = lmdb.open(LMDB, readonly=True, lock=False, readahead=True, meminit=False)\n",
    "with DB.begin(write=False) as txn:\n",
    "    KEYS = pickle.loads(txn.get('__keys__'.encode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "829dc72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /pscratch/sd/a/ahhyun/EcoGFound/DATA/scaling_data_V2_Sep_2025/striped_EEG_lmdb\n",
    "# 아현썜 pscratch의 데이터 경로 당장은 그냥 써도 되지만 추후 내 pscratch나 m4727 등으로 옮겨서 사용할 것\n",
    "\n",
    "class Physio_for_SOLID_from_lmdb(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            lmdb_dir: str,\n",
    "            maxfold: int,\n",
    "            targetfold: int,\n",
    "            seed: int,\n",
    "            train: bool,\n",
    "            split_by_sub: bool,\n",
    "    ):\n",
    "        random_seed(seed)\n",
    "        self.seed = seed\n",
    "        self.lmdb_dir = lmdb_dir\n",
    "        self.db = lmdb.open(lmdb_dir, readonly=True, lock=False, readahead=True, meminit=False)\n",
    "        with self.db.begin(write=False) as txn:\n",
    "            self.lmdb_keys = pickle.loads(txn.get('__keys__'.encode()))\n",
    "\n",
    "        self.train = train\n",
    "        self.split_by_sub = split_by_sub\n",
    "\n",
    "        self.maxfold = maxfold\n",
    "        self.targetfold = targetfold\n",
    "        self.data, self.target, self.data_meta, self.target_meta = self.make_data_and_target_by_fold(self.targetfold, self.lmdb_keys, \n",
    "                                                                   self.maxfold, self.split_by_sub, self.seed)\n",
    "\n",
    "    def make_data_and_target_by_fold(self, fold, lmdb_keys, maxfold, split_by_sub, seed):\n",
    "        self.record = []\n",
    "\n",
    "        train_data = {'input': [], 'target': [], 'input_meta': [], 'target_meta': []}\n",
    "        test_data  = {'input': [], 'target': [], 'input_meta': [], 'target_meta': []}\n",
    "\n",
    "        train_data_keys_in_lmdb, test_data_keys_in_lmdb = train_test_split_by_fold_num(fold, lmdb_keys, maxfold, split_by_sub, seed)\n",
    "\n",
    "\n",
    "        if self.train:\n",
    "            for train_data_key in train_data_keys_in_lmdb:\n",
    "\n",
    "                # TODO : get proper seg_in and seg_out by input idx\n",
    "                seg_in, seg_out, seg_in_meta, seg_out_meta = self.segmentation_from_idx(train_data_key, self.db)\n",
    "\n",
    "                train_data['input'] += seg_in\n",
    "                train_data['target'] += seg_out\n",
    "                train_data['input_meta'] += seg_in_meta\n",
    "                train_data['target_meta']+= seg_out_meta\n",
    "\n",
    "            return (train_data['input'], train_data['target'],\n",
    "                    train_data['input_meta'], train_data['target_meta'])\n",
    "        \n",
    "        else:\n",
    "            for test_data_key in test_data_keys_in_lmdb:\n",
    "\n",
    "                seg_in, seg_out, seg_in_meta, seg_out_meta = self.segmentation_from_idx(test_data_key, self.db)\n",
    "\n",
    "                test_data['input'] += seg_in\n",
    "                test_data['target'] += seg_out\n",
    "                test_data['input_meta']  += seg_in_meta\n",
    "                test_data['target_meta'] += seg_out_meta\n",
    "                \n",
    "            return (test_data['input'], test_data['target'],\n",
    "                    test_data['input_meta'], test_data['target_meta'])\n",
    "\n",
    "\n",
    "\n",
    "    def lmdb_get(self, env, key):\n",
    "        if isinstance(key, str):\n",
    "            key = key.encode(\"utf-8\")\n",
    "        with env.begin(write=False) as txn:\n",
    "            v = txn.get(key)\n",
    "        if v is None:\n",
    "            raise KeyError(f\"Key not found: {key}\")\n",
    "        return pickle.loads(v)\n",
    "\n",
    "    def segmentation_from_idx(self, key, lmdb_db, in_len=99, out_len=1, stride=1):\n",
    "        \"\"\"\n",
    "        eeg_data_ : (C, L)  e.g. (64, 800)\n",
    "\n",
    "        sliding:\n",
    "          input  = eeg[:, t:t+99]\n",
    "          target = eeg[:, t+99:t+100]  (1 step)\n",
    "        \"\"\"\n",
    "        sample_for_key = self.lmdb_get(lmdb_db, key)\n",
    "\n",
    "        channel_name = sample_for_key['data_info']['channel_names']  # len=C\n",
    "        eeg_data = sample_for_key['sample']                         # (C, T, Fs)\n",
    "        eeg_data_ = rearrange(eeg_data, 'c t f -> c (t f)')         # (C, L)\n",
    "        eeg_data_ = torch.from_numpy(eeg_data_).to(torch.float32)\n",
    "\n",
    "        C, L = eeg_data_.shape\n",
    "        total_needed = in_len + out_len\n",
    "\n",
    "        if L < total_needed:\n",
    "            return [], [], [], []\n",
    "\n",
    "        seg_in_list = []\n",
    "        seg_out_list = []\n",
    "        seg_in_meta_list = []\n",
    "        seg_out_meta_list = []\n",
    "\n",
    "        for t in range(0, L - total_needed + 1, stride):\n",
    "            x = eeg_data_[:, t : t + in_len]                         # (C, 99)\n",
    "            y = eeg_data_[:, t + in_len : t + in_len + out_len]      # (C, 1)\n",
    "\n",
    "            seg_in_list.append(x)\n",
    "            seg_out_list.append(y)\n",
    "\n",
    "            seg_in_meta_list.append(channel_name)\n",
    "            seg_out_meta_list.append(channel_name)\n",
    "\n",
    "        return seg_in_list, seg_out_list, seg_in_meta_list, seg_out_meta_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        i  = self.data[idx]\n",
    "        o  = self.target[idx]\n",
    "        im = self.data_meta[idx]\n",
    "        om = self.target_meta[idx]\n",
    "        return i, o, im, om"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe198315",
   "metadata": {},
   "outputs": [],
   "source": [
    "TORCHEEG_2DGRID = [\n",
    "    ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'],\n",
    "    ['-', '-', '-', '-', 'FP1', 'FPZ', 'FP2', '-', '-', '-', '-'],\n",
    "    ['-', '-', 'AF7', '-', 'AF3', 'AFZ', 'AF4', '-', 'AF8', '-', '-'],\n",
    "    ['F9', 'F7', 'F5', 'F3', 'F1', 'FZ', 'F2', 'F4', 'F6', 'F8', 'F10'],\n",
    "    ['FT9', 'FT7', 'FC5', 'FC3', 'FC1', 'FCZ', 'FC2', 'FC4', 'FC6', 'FT8', 'FT10'], \n",
    "    ['T9', 'T7', 'C5', 'C3', 'C1', 'CZ', 'C2', 'C4', 'C6', 'T8', 'T10'],\n",
    "    ['TP9', 'TP7', 'CP5', 'CP3', 'CP1', 'CPZ', 'CP2', 'CP4', 'CP6', 'TP8', 'TP10'], \n",
    "    ['P9', 'P7', 'P5', 'P3', 'P1', 'PZ', 'P2', 'P4', 'P6', 'P8', 'P10'],\n",
    "    ['-', '-', 'PO7', 'PO5', 'PO3', 'POZ', 'PO4', 'PO6', 'PO8', '-', '-'],\n",
    "    ['-', '-', '-', 'CB1', 'O1', 'OZ', 'O2', 'CB2', '-', '-', '-'],\n",
    "    ['-', '-', '-', '-', '-', 'IZ', '-', '-', '-', '-', '-']\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b846b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_channel_to_rc(grid_2d):\n",
    "    ch2rc = {}\n",
    "    H = len(grid_2d)\n",
    "    W = len(grid_2d[0])\n",
    "    for r in range(H):\n",
    "        for c in range(W):\n",
    "            ch = grid_2d[r][c]\n",
    "            if ch != '-' and ch is not None:\n",
    "                ch2rc[str(ch).strip().upper()] = (r, c)\n",
    "    return ch2rc, H, W\n",
    "\n",
    "CHANNEL_TO_RC, H, W = build_channel_to_rc(TORCHEEG_2DGRID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1333ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splat_eeg_grid(eeg_cl, channel_names, channel_to_rc=CHANNEL_TO_RC, H=H, W=W):\n",
    "    \"\"\"\n",
    "    eeg_cl: (C, L) torch.Tensor (권장)\n",
    "    channel_names: list[str] len=C\n",
    "    returns:\n",
    "      grid: (L, H, W)\n",
    "      mask: (H, W)\n",
    "    \"\"\"\n",
    "    if not torch.is_tensor(eeg_cl):\n",
    "        eeg_cl = torch.as_tensor(eeg_cl)\n",
    "\n",
    "    assert eeg_cl.dim() == 2, f\"Expected (C,L), got {tuple(eeg_cl.shape)}\"\n",
    "    C, L = eeg_cl.shape\n",
    "    device = eeg_cl.device\n",
    "\n",
    "    grid = torch.zeros((L, H, W), dtype=eeg_cl.dtype, device=device)\n",
    "    cnt  = torch.zeros((H, W), dtype=torch.float32, device=device)\n",
    "\n",
    "    for ci in range(C):\n",
    "        ch = str(channel_names[ci]).strip().upper()\n",
    "        if ch in channel_to_rc:\n",
    "            r, c = channel_to_rc[ch]\n",
    "            grid[:, r, c] += eeg_cl[ci, :]\n",
    "            cnt[r, c] += 1.0\n",
    "\n",
    "    mask = (cnt > 0).float()\n",
    "    grid = torch.where(cnt > 0, grid / torch.clamp(cnt, min=1.0), grid)\n",
    "    return grid, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d62ffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGToGridCtx9(Dataset):\n",
    "    \"\"\"\n",
    "    base[idx] -> (i, o, im, om)\n",
    "      i : (C, 99)   (torch or numpy)\n",
    "      o : (C, 1)\n",
    "      im: channel list\n",
    "      om: channel list\n",
    "\n",
    "    return:\n",
    "      x0       : (1,H,W)\n",
    "      tgt_mask : (1,H,W)\n",
    "      cond     : (20,H,W) = [lat_map, lon_map, past_grids(9), past_masks(9)]\n",
    "      mean, std\n",
    "    \"\"\"\n",
    "    def __init__(self, base_dataset, squash_tanh=True, channel_to_rc=CHANNEL_TO_RC):\n",
    "        self.base = base_dataset\n",
    "        self.squash = squash_tanh\n",
    "        self.channel_to_rc = channel_to_rc\n",
    "\n",
    "        self.mean = float(getattr(self.base, \"mean\", 0.0))\n",
    "        self.std  = float(getattr(self.base, \"std\",  1.0))\n",
    "\n",
    "        lat = torch.linspace(0, 1, H).unsqueeze(1).repeat(1, W)\n",
    "        lon = torch.linspace(0, 1, W).unsqueeze(0).repeat(H, 1)\n",
    "        self.lat_map = lat\n",
    "        self.lon_map = lon\n",
    "\n",
    "        self.ctx_steps = 9\n",
    "        self.in_len = 99\n",
    "        assert self.in_len % self.ctx_steps == 0, \"can not dividable\"\n",
    "        self.bin = self.in_len // self.ctx_steps  # 11\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i, o, im, om = self.base[idx]  # i:(C,99), o:(C,1), im/om: channel list\n",
    "\n",
    "        if not torch.is_tensor(i): i = torch.as_tensor(i)\n",
    "        if not torch.is_tensor(o): o = torch.as_tensor(o)\n",
    "\n",
    "        # ---- build past 9 step grids/masks from encoder ----\n",
    "        past_grids, past_masks = [], []\n",
    "\n",
    "        for k in range(self.ctx_steps):\n",
    "            seg = i[:, k*self.bin:(k+1)*self.bin]      # (C,11)\n",
    "            vals = seg.mean(dim=1, keepdim=True)       # (C,1)\n",
    "\n",
    "            grid_k, mask_k = splat_eeg_grid(vals, im, self.channel_to_rc, H, W)  # grid:(1,H,W)\n",
    "            grid_k = grid_k.squeeze(0)  # (H,W)\n",
    "\n",
    "            if self.squash:\n",
    "                grid_k = torch.tanh(grid_k)\n",
    "\n",
    "            past_grids.append(grid_k)\n",
    "            past_masks.append(mask_k)\n",
    "\n",
    "        past_grids = torch.stack(past_grids, 0)  # (9,H,W)\n",
    "        past_masks = torch.stack(past_masks, 0)  # (9,H,W)\n",
    "\n",
    "        # ---- target (next slot) grid/mask ----\n",
    "        tgt_grid, tgt_mask = splat_eeg_grid(o, om, self.channel_to_rc, H, W)  # tgt_grid:(1,H,W)\n",
    "        tgt_grid = tgt_grid.squeeze(0)    # (H,W)\n",
    "\n",
    "        x0 = torch.tanh(tgt_grid) if self.squash else tgt_grid\n",
    "\n",
    "        # ---- cond channels ----\n",
    "        cond = torch.cat([\n",
    "            self.lat_map.unsqueeze(0),  # (1,H,W)\n",
    "            self.lon_map.unsqueeze(0),  # (1,H,W)\n",
    "            past_grids,                 # (9,H,W)\n",
    "            past_masks                  # (9,H,W)\n",
    "        ], dim=0)  # (20,H,W)\n",
    "\n",
    "        return x0.unsqueeze(0), tgt_mask.unsqueeze(0), cond, self.mean, self.std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fb329a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set seed 41 is done\n"
     ]
    }
   ],
   "source": [
    "sample_dataset = Physio_for_SOLID_from_lmdb(lmdb_dir='/pscratch/sd/t/tylee/Dataset/PhysioNet_200Hz_for_SOLID',\n",
    "                                            maxfold = 5,\n",
    "                                            targetfold=0,\n",
    "                                            seed=41,\n",
    "                                            train=True,\n",
    "                                            split_by_sub=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00fbd319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 11, 11]) torch.Size([1, 11, 11]) torch.Size([20, 11, 11]) 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "grid_ds = EEGToGridCtx9(sample_dataset)\n",
    "\n",
    "x, mask, cond, mean, std = grid_ds[0]\n",
    "print(x.shape, mask.shape, cond.shape, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc4898c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set seed 41 is done\n",
      "set seed 41 is done\n"
     ]
    }
   ],
   "source": [
    "sample_train_dataset = Physio_for_SOLID_from_lmdb(lmdb_dir='/pscratch/sd/t/tylee/Dataset/PhysioNet_200Hz_for_SOLID',\n",
    "                                            maxfold = 5,\n",
    "                                            targetfold=0,\n",
    "                                            seed=41,\n",
    "                                            train=True,\n",
    "                                            split_by_sub=True)\n",
    "\n",
    "sample_test_dataset = Physio_for_SOLID_from_lmdb(lmdb_dir='/pscratch/sd/t/tylee/Dataset/PhysioNet_200Hz_for_SOLID',\n",
    "                                            maxfold = 5,\n",
    "                                            targetfold=0,\n",
    "                                            seed=41,\n",
    "                                            train=False,\n",
    "                                            split_by_sub=True)\n",
    "\n",
    "train_grid_dataset = EEGToGridCtx9(sample_train_dataset)\n",
    "test_grid_dataset = EEGToGridCtx9(sample_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "273fda92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_grid_dataset, batch_size=16, shuffle=True, drop_last=True, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_grid_dataset, batch_size=16, shuffle=False, drop_last=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e7b0847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, numpy as np\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from einops import rearrange\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5489d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "RESULT_DIR = '/pscratch/sd/t/tylee/SOLID_EEG_RESULT'\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "LR = 2e-4\n",
    "TIME_STEPS = 1000                  # diffusion T\n",
    "TOTAL_STEPS = 150_000\n",
    "LOG_EVERY  = 200\n",
    "EVAL_EVERY = 1000\n",
    "SAVE_SAMPLES_EVERY = 1000\n",
    "BG_WEIGHT = 0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f1e17f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5490933\n",
      "1404804\n"
     ]
    }
   ],
   "source": [
    "# Model implementation from Kevin\n",
    "print(len(train_grid_dataset))\n",
    "print(len(test_grid_dataset))\n",
    "\n",
    "# ============================================================\n",
    "# 3) UNet (no attention; rectangular-friendly)\n",
    "# ============================================================\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, dim_out=None, time_emb_dim=None, dropout=0.0, groups=32):\n",
    "        super().__init__()\n",
    "        dim_out = dim if dim_out is None else dim_out\n",
    "        self.mlp = nn.Sequential(nn.SiLU(), nn.Linear(time_emb_dim, dim_out)) if time_emb_dim else None\n",
    "        self.norm1 = nn.GroupNorm(groups, dim);     self.conv1 = nn.Conv2d(dim, dim_out, 3, padding=1)\n",
    "        self.norm2 = nn.GroupNorm(groups, dim_out); self.conv2 = nn.Conv2d(dim_out, dim_out, 3, padding=1)\n",
    "        self.dropout = nn.Dropout(dropout) if dropout else nn.Identity()\n",
    "        self.act = nn.SiLU()\n",
    "        self.res = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
    "    def forward(self, x, t_emb=None):\n",
    "        h = self.conv1(self.act(self.norm1(x)))\n",
    "        if self.mlp is not None and t_emb is not None:\n",
    "            h = h + self.mlp(t_emb)[..., None, None]\n",
    "        h = self.conv2(self.dropout(self.act(self.norm2(h))))\n",
    "        return h + self.res(x)\n",
    "\n",
    "\n",
    "class SinusoidalTimeEmbedding(nn.Module):\n",
    "    def __init__(self, base_dim):\n",
    "        super().__init__()\n",
    "        self.out_dim = base_dim\n",
    "    def forward(self, t):  # t: (B,)\n",
    "        # classic transformer-style PE on scalar t\n",
    "        half = self.out_dim // 2\n",
    "        device = t.device\n",
    "        freqs = torch.exp(torch.arange(half, device=device).float()\n",
    "                          * -(math.log(10000.0) / max(1, half-1)))\n",
    "        ang = t.float().unsqueeze(1) * freqs.unsqueeze(0)  # (B, half)\n",
    "        emb = torch.cat([torch.sin(ang), torch.cos(ang)], dim=1)  # (B, 2*half)\n",
    "        if emb.shape[1] < self.out_dim:\n",
    "            emb = F.pad(emb, (0, self.out_dim - emb.shape[1]))\n",
    "        return emb\n",
    "\n",
    "class TimeMLP(nn.Module):\n",
    "    def __init__(self, base_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1, base_dim*4), nn.SiLU(),\n",
    "            nn.Linear(base_dim*4, base_dim*4)\n",
    "        )\n",
    "    def forward(self, t):  # (B,)\n",
    "        return self.net(t[:,None].float())\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, base_dim=128, dim_mults=(1,2,4),\n",
    "                 in_channels=1+20, image_size=(H,W), dropout=0.0, groups=32):\n",
    "        super().__init__()\n",
    "        self.image_h, self.image_w = image_size\n",
    "        self.time_dim = base_dim * 4\n",
    "\n",
    "        # self.time_pe  = SinusoidalTimeEmbedding(base_dim)\n",
    "        # self.time_mlp = nn.Sequential(\n",
    "        #     nn.Linear(base_dim, self.time_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.time_dim, self.time_dim)\n",
    "        # )\n",
    "        self.time_mlp = TimeMLP(base_dim)\n",
    "        self.init = nn.Conv2d(in_channels, base_dim, 3, padding=1)\n",
    "\n",
    "        self.downs = nn.ModuleList()\n",
    "        in_ch = base_dim\n",
    "        skip_channels = []\n",
    "        for li, m in enumerate(dim_mults):\n",
    "            out_ch = base_dim * m\n",
    "            rb1 = ResnetBlock(in_ch, out_ch, self.time_dim, dropout, groups); self.downs.append(rb1); in_ch = out_ch; skip_channels.append(in_ch)\n",
    "            rb2 = ResnetBlock(in_ch, out_ch, self.time_dim, dropout, groups); self.downs.append(rb2); in_ch = out_ch; skip_channels.append(in_ch)\n",
    "            if li != len(dim_mults) - 1:\n",
    "                self.downs.append(nn.Conv2d(in_ch, in_ch, 3, stride=2, padding=1))\n",
    "\n",
    "        self.mid1 = ResnetBlock(in_ch, in_ch, self.time_dim, dropout, groups)\n",
    "        self.mid2 = ResnetBlock(in_ch, in_ch, self.time_dim, dropout, groups)\n",
    "\n",
    "        self.ups, self.kinds = nn.ModuleList(), []\n",
    "        sc = skip_channels.copy()\n",
    "        for li, m in enumerate(reversed(dim_mults)):\n",
    "            out_ch = base_dim * m\n",
    "            for _ in range(2):\n",
    "                skip_ch = sc.pop()\n",
    "                self.ups.append(ResnetBlock(in_ch + skip_ch, out_ch, self.time_dim, dropout, groups)); self.kinds.append('res')\n",
    "                in_ch = out_ch\n",
    "            if li != len(dim_mults) - 1:\n",
    "                self.ups.append(nn.Upsample(scale_factor=2, mode='nearest')); self.kinds.append('up')\n",
    "                self.ups.append(nn.Conv2d(in_ch, in_ch, 3, padding=1));       self.kinds.append('conv')\n",
    "\n",
    "        self.final = nn.Sequential(nn.GroupNorm(groups, in_ch), nn.SiLU(), nn.Conv2d(in_ch, 1, 3, padding=1))\n",
    "\n",
    "    def forward(self, x_cat, t):\n",
    "        # t_emb = self.time_mlp(self.time_pe(t))\n",
    "        t_emb = self.time_mlp(t)\n",
    "        skips, h = [], self.init(x_cat)\n",
    "        for layer in self.downs:\n",
    "            if isinstance(layer, ResnetBlock):\n",
    "                h = layer(h, t_emb); skips.append(h)\n",
    "            else:\n",
    "                h = layer(h)\n",
    "        h = self.mid1(h, t_emb); h = self.mid2(h, t_emb)\n",
    "        for kind, layer in zip(self.kinds, self.ups):\n",
    "            if kind == 'res':\n",
    "                s = skips.pop()\n",
    "                if s.shape[-2:] != h.shape[-2:]:\n",
    "                    s = F.interpolate(s, size=h.shape[-2:], mode='nearest')\n",
    "                h = layer(torch.cat([h, s], dim=1), t_emb)\n",
    "            elif kind == 'up':\n",
    "                h = layer(h)\n",
    "            else:\n",
    "                h = layer(h)\n",
    "        if h.shape[-2:] != (self.image_h, self.image_w):\n",
    "            h = F.interpolate(h, size=(self.image_h, self.image_w), mode='nearest')\n",
    "        return self.final(h)\n",
    "\n",
    "# ============================================================\n",
    "# 4) Diffusion core — noise only target channel; cond is clean\n",
    "# ============================================================\n",
    "class GaussianDiffusion(nn.Module):\n",
    "    def __init__(self, unet, image_size=(H,W), time_steps=TIME_STEPS, loss_type='l2'):\n",
    "        super().__init__()\n",
    "        self.unet = unet\n",
    "        self.H, self.W = image_size\n",
    "        self.T = time_steps\n",
    "        self.loss_type = loss_type\n",
    "\n",
    "        beta  = self.linear_beta_schedule(time_steps)\n",
    "        alpha = 1. - beta\n",
    "        abar  = torch.cumprod(alpha, dim=0)\n",
    "        abar_prev = F.pad(abar[:-1], (1,0), value=1.)\n",
    "\n",
    "        self.register_buffer('beta', beta)\n",
    "        self.register_buffer('alpha', alpha)\n",
    "        self.register_buffer('alpha_bar', abar)\n",
    "        self.register_buffer('alpha_bar_prev', abar_prev)\n",
    "        self.register_buffer('sqrt_alpha_bar', torch.sqrt(abar))\n",
    "        self.register_buffer('sqrt_one_minus_alpha_bar', torch.sqrt(1 - abar))\n",
    "        self.register_buffer('sqrt_recip_alpha_bar', torch.sqrt(1. / abar))\n",
    "        self.register_buffer('sqrt_recip_alpha_bar_min_1', torch.sqrt(1. / abar - 1))\n",
    "        self.register_buffer('sqrt_recip_alpha', torch.sqrt(1. / alpha))\n",
    "        self.register_buffer('beta_over_sqrt_one_minus_alpha_bar', beta / torch.sqrt(1. - abar))\n",
    "\n",
    "    def linear_beta_schedule(self, T):\n",
    "        scale = 1000 / T\n",
    "        return torch.linspace(scale*1e-4, scale*2e-2, T, dtype=torch.float32)\n",
    "\n",
    "    def q_sample(self, x0, t, noise):\n",
    "        return self.sqrt_alpha_bar[t][:,None,None,None] * x0 + \\\n",
    "               self.sqrt_one_minus_alpha_bar[t][:,None,None,None] * noise\n",
    "\n",
    "    def forward(self, x0, mask, cond):\n",
    "        \"\"\"\n",
    "        x0:   (B,1,H,W) in tanh(z) space\n",
    "        mask: (B,1,H,W)  (1=observed bin in target; 0=unobserved)\n",
    "        cond: (B,20,H,W) = [lat, lon, past_grids(9), past_masks(9)]\n",
    "        \"\"\"\n",
    "        b = x0.size(0)\n",
    "        t = torch.randint(0, self.T, (b,), device=x0.device).long()\n",
    "\n",
    "        noise = torch.randn_like(x0)\n",
    "        x_t   = self.q_sample(x0, t, noise)\n",
    "        x_cat = torch.cat([x_t, cond], dim=1)  # noised target + clean cond\n",
    "\n",
    "        pred = self.unet(x_cat, t)  # predict noise on target channel\n",
    "\n",
    "        if self.loss_type == 'l1':\n",
    "            raw = F.l1_loss(noise, pred, reduction='none')\n",
    "        elif self.loss_type == 'l2':\n",
    "            raw = F.mse_loss(noise, pred, reduction='none')\n",
    "        else:\n",
    "            raw = F.smooth_l1_loss(noise, pred, reduction='none')\n",
    "\n",
    "        w = mask + BG_WEIGHT  # supervise observed bins + tiny everywhere\n",
    "        return (raw * w).sum() / (w.sum() + 1e-8)\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def p_sample(self, xt, cond, t, clip=True):\n",
    "        bt = torch.full((xt.shape[0],), t, device=xt.device, dtype=torch.long)\n",
    "        x_cat = torch.cat([xt, cond], dim=1)\n",
    "        pred_noise = self.unet(x_cat, bt)\n",
    "\n",
    "        def bcast(x): return x.view(-1,1,1,1)\n",
    "        if clip:\n",
    "            x0 = bcast(self.sqrt_recip_alpha_bar[bt]) * xt - bcast(self.sqrt_recip_alpha_bar_min_1[bt]) * pred_noise\n",
    "            x0 = x0.clamp(-1., 1.)\n",
    "            c1 = self.beta[bt] * torch.sqrt(self.alpha_bar_prev[bt]) / (1. - self.alpha_bar[bt])\n",
    "            c2 = torch.sqrt(self.alpha[bt]) * (1. - self.alpha_bar_prev[bt]) / (1. - self.alpha[bt])\n",
    "            mean = bcast(c1) * x0 + bcast(c2) * xt\n",
    "        else:\n",
    "            mean = bcast(self.sqrt_recip_alpha[bt]) * (xt - bcast(self.beta_over_sqrt_one_minus_alpha_bar[bt]) * pred_noise)\n",
    "        var = self.beta[bt] * ((1. - self.alpha_bar_prev[bt]) / (1. - self.alpha_bar[bt]))\n",
    "        noise = torch.randn_like(xt) if t > 0 else 0.\n",
    "        return mean + torch.sqrt(bcast(var)) * noise\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def sample(self, cond, clip=False):  # clip=False often gives crisper fields\n",
    "        b = cond.size(0)\n",
    "        x = torch.randn((b,1,self.H,self.W), device=cond.device)\n",
    "        for t in reversed(range(self.T)):\n",
    "            x = self.p_sample(x, cond, t, clip=clip)\n",
    "        return x.clamp(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c60d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train(ctx9):   0%|          | 185/150000 [00:23<5:15:35,  7.91it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 203\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m         x0, msk, cond, mu, std \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    205\u001b[0m         it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(train_loader)\n",
      "File \u001b[0;32m~/.conda/envs/solid_eeg/lib/python3.10/site-packages/torch/utils/data/dataloader.py:732\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 732\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    738\u001b[0m ):\n",
      "File \u001b[0;32m~/.conda/envs/solid_eeg/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1482\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data, worker_id)\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1482\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1485\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/solid_eeg/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1434\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1432\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1433\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1434\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1435\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1436\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.conda/envs/solid_eeg/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1275\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1272\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1273\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1274\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1275\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1278\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/solid_eeg/lib/python3.10/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/.conda/envs/solid_eeg/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 6) Build model + diffusion + optimizer\n",
    "# ============================================================\n",
    "IN_CHANNELS = 1 + 2 + 9 + 9   # target(noised) + lat/lon + 9 past grids + 9 past masks = 21\n",
    "unet = UNet(base_dim=128, dim_mults=(1,2,4), in_channels=IN_CHANNELS, image_size=(H,W)).to(DEVICE)\n",
    "diffusion = GaussianDiffusion(unet, image_size=(H,W), time_steps=TIME_STEPS, loss_type='l2').to(DEVICE)\n",
    "\n",
    "# ---- CosineAnnealingWarmupRestarts setup ----\n",
    "from torch.optim import AdamW\n",
    "from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
    "\n",
    "max_lr = 4e-4\n",
    "min_lr = 8e-6\n",
    "TOTAL_ITERS = TOTAL_STEPS          # keep these tied\n",
    "warmup_steps = max(1, int(0.1 * TOTAL_ITERS))\n",
    "weight_decay = 1e-4\n",
    "\n",
    "opt = AdamW(diffusion.parameters(), lr=max_lr, betas=(0.9, 0.999), weight_decay=weight_decay)\n",
    "\n",
    "sched = CosineAnnealingWarmupRestarts(\n",
    "    optimizer=opt,\n",
    "    first_cycle_steps=TOTAL_ITERS,  # single full-length cosine cycle\n",
    "    max_lr=max_lr,\n",
    "    min_lr=min_lr,\n",
    "    warmup_steps=warmup_steps,\n",
    "    gamma=1.0                       # no decay across cycles since we use one cycle\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 7) Utilities: invert tanh->raw and metrics\n",
    "# ============================================================\n",
    "def inv_tanh_to_raw(x_tanh, mean, std):\n",
    "    z = torch.atanh(x_tanh.clamp(-0.999, 0.999))\n",
    "    return z * std + mean\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_rmse(diffusion, loader): # add mini batch to check fast\n",
    "    mse_sum_raw = 0.0; w_sum = 0.0\n",
    "    mse_sum_norm = 0.0\n",
    "    for x0_te, m_te, c_te, mu_te, std_te in loader:\n",
    "        x0_te  = x0_te.to(DEVICE)   # tanh(z)\n",
    "        m_te   = m_te.to(DEVICE)\n",
    "        c_te   = c_te.to(DEVICE)\n",
    "        mu_te  = mu_te.to(DEVICE)[:,None,None,None]\n",
    "        std_te = std_te.to(DEVICE)[:,None,None,None]\n",
    "\n",
    "        xhat = diffusion.sample(c_te, clip=False)             # tanh(z)\n",
    "        # raw µg/m³\n",
    "        raw_hat = inv_tanh_to_raw(xhat,  mu_te, std_te)\n",
    "        raw_gt  = inv_tanh_to_raw(x0_te, mu_te, std_te)\n",
    "\n",
    "        mse_sum_raw  += ((raw_hat - raw_gt)**2 * m_te).sum().item()\n",
    "        w_sum        += m_te.sum().item()\n",
    "        # normalized (z) space RMSE (mask)\n",
    "        zhat = torch.atanh(xhat.clamp(-0.999, 0.999))\n",
    "        zgt  = torch.atanh(x0_te.clamp(-0.999, 0.999))\n",
    "        mse_sum_norm += ((zhat - zgt)**2 * m_te).sum().item()\n",
    "\n",
    "    rmse_raw  = math.sqrt(mse_sum_raw / max(w_sum, 1e-8))\n",
    "    rmse_norm = math.sqrt(mse_sum_norm / max(w_sum, 1e-8))\n",
    "    return rmse_raw, rmse_norm, int(w_sum)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_rmse_minibatch(diffusion, loader, max_batches=None): # add mini batch to check fast\n",
    "    mse_sum_raw = 0.0; w_sum = 0.0\n",
    "    mse_sum_norm = 0.0\n",
    "    for i, batch in enumerate(loader):\n",
    "        if (max_batches is not None) and (i >= max_batches):\n",
    "            break\n",
    "        x0_te, m_te, c_te, mu_te, std_te = batch\n",
    "    # for x0_te, m_te, c_te, mu_te, std_te in loader:\n",
    "        x0_te  = x0_te.to(DEVICE)   # tanh(z)\n",
    "        m_te   = m_te.to(DEVICE)\n",
    "        c_te   = c_te.to(DEVICE)\n",
    "        mu_te  = mu_te.to(DEVICE)[:,None,None,None]\n",
    "        std_te = std_te.to(DEVICE)[:,None,None,None]\n",
    "\n",
    "        xhat = diffusion.sample(c_te, clip=False)             # tanh(z)\n",
    "        # raw µg/m³\n",
    "        raw_hat = inv_tanh_to_raw(xhat,  mu_te, std_te)\n",
    "        raw_gt  = inv_tanh_to_raw(x0_te, mu_te, std_te)\n",
    "\n",
    "        mse_sum_raw  += ((raw_hat - raw_gt)**2 * m_te).sum().item()\n",
    "        w_sum        += m_te.sum().item()\n",
    "        # normalized (z) space RMSE (mask)\n",
    "        zhat = torch.atanh(xhat.clamp(-0.999, 0.999))\n",
    "        zgt  = torch.atanh(x0_te.clamp(-0.999, 0.999))\n",
    "        mse_sum_norm += ((zhat - zgt)**2 * m_te).sum().item()\n",
    "\n",
    "    rmse_raw  = math.sqrt(mse_sum_raw / max(w_sum, 1e-8))\n",
    "    rmse_norm = math.sqrt(mse_sum_norm / max(w_sum, 1e-8))\n",
    "    return rmse_raw, rmse_norm, int(w_sum)\n",
    "\n",
    "import math\n",
    "\n",
    "@torch.no_grad()\n",
    "def _crps_from_ensemble(y_flat, samples_flat):\n",
    "    \"\"\"\n",
    "    y_flat:        (N,) ground-truth vector (masked entries only later)\n",
    "    samples_flat:  (K,N) ensemble samples\n",
    "    returns:       (N,) CRPS per entry\n",
    "    \"\"\"\n",
    "    K = samples_flat.shape[0]\n",
    "    # term1 = E|X - y|  ≈ (1/K) Σ_i |x_i - y|\n",
    "    term1 = (samples_flat - y_flat.unsqueeze(0)).abs().mean(dim=0)  # (N,)\n",
    "    # term2 = 0.5 * E|X - X'| ≈ 0.5 * (1/K^2) Σ_ij |x_i - x_j|\n",
    "    diffs = samples_flat.unsqueeze(0) - samples_flat.unsqueeze(1)   # (K,K,N)\n",
    "    term2 = 0.5 * diffs.abs().mean(dim=(0,1))                      # (N,)\n",
    "    return term1 - term2                                            # (N,)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_crps_and_points(diffusion, loader, K=10, clip=False):\n",
    "    \"\"\"\n",
    "    Returns masked dataset-averaged:\n",
    "      CRPS_raw, CRPS_norm, MAE_raw, RMSE_raw, MAE_norm, RMSE_norm, n_obs_bins\n",
    "    \"\"\"\n",
    "    crps_raw_sum = 0.0\n",
    "    crps_norm_sum = 0.0\n",
    "    mae_raw_sum = 0.0\n",
    "    rmse_raw_sum = 0.0\n",
    "    mae_norm_sum = 0.0\n",
    "    rmse_norm_sum = 0.0\n",
    "    w_sum = 0.0\n",
    "\n",
    "    for x0_te, m_te, c_te, mu_te, std_te in loader:\n",
    "        x0_te  = x0_te.to(DEVICE)          # (B,1,H,W), tanh(z)\n",
    "        m_te   = m_te.to(DEVICE)           # (B,1,H,W) mask\n",
    "        c_te   = c_te.to(DEVICE)           # (B,20,H,W)\n",
    "        mu_te  = mu_te.to(DEVICE)[:,None,None,None]\n",
    "        std_te = std_te.to(DEVICE)[:,None,None,None]\n",
    "\n",
    "        B, _, H, W = x0_te.shape\n",
    "        N = B*H*W\n",
    "        mask_flat = m_te.view(N).bool()\n",
    "\n",
    "        # K samples\n",
    "        samples = []\n",
    "        for _ in range(K):\n",
    "            xhat = diffusion.sample(c_te, clip=clip)             # (B,1,H,W) tanh(z)\n",
    "            samples.append(xhat)\n",
    "        S = torch.stack(samples, dim=0)                          # (K,B,1,H,W)\n",
    "\n",
    "        # normalized (z)\n",
    "        z_gt  = torch.atanh(x0_te.clamp(-0.999, 0.999))          # (B,1,H,W)\n",
    "        z_smp = torch.atanh(S.clamp(-0.999, 0.999))              # (K,B,1,H,W)\n",
    "\n",
    "        # raw μg/m³\n",
    "        raw_gt  = z_gt * std_te + mu_te                          # (B,1,H,W)\n",
    "        raw_smp = z_smp * std_te + mu_te                         # (K,B,1,H,W)\n",
    "\n",
    "        # flatten\n",
    "        z_gt_f   = z_gt.view(N)\n",
    "        raw_gt_f = raw_gt.view(N)\n",
    "        z_smp_f  = z_smp.view(K, N)\n",
    "        raw_smp_f= raw_smp.view(K, N)\n",
    "\n",
    "        # CRPS (masked mean)\n",
    "        crps_norm = _crps_from_ensemble(z_gt_f,   z_smp_f)[mask_flat].mean()\n",
    "        crps_raw  = _crps_from_ensemble(raw_gt_f, raw_smp_f)[mask_flat].mean()\n",
    "        crps_norm_sum += crps_norm.item() * mask_flat.sum().item()\n",
    "        crps_raw_sum  += crps_raw.item()  * mask_flat.sum().item()\n",
    "\n",
    "        # point forecast = ensemble mean\n",
    "        z_mean   = z_smp.mean(dim=0).view(N)\n",
    "        raw_mean = raw_smp.mean(dim=0).view(N)\n",
    "\n",
    "        # MAE/RMSE (masked)\n",
    "        mae_norm_sum  += (z_mean - z_gt_f).abs()[mask_flat].sum().item()\n",
    "        rmse_norm_sum += ((z_mean - z_gt_f)**2)[mask_flat].sum().item()\n",
    "        mae_raw_sum   += (raw_mean - raw_gt_f).abs()[mask_flat].sum().item()\n",
    "        rmse_raw_sum  += ((raw_mean - raw_gt_f)**2)[mask_flat].sum().item()\n",
    "\n",
    "        w_sum += mask_flat.sum().item()\n",
    "\n",
    "    CRPS_raw  = crps_raw_sum  / max(w_sum, 1e-8)\n",
    "    CRPS_norm = crps_norm_sum / max(w_sum, 1e-8)\n",
    "    MAE_raw   = mae_raw_sum   / max(w_sum, 1e-8)\n",
    "    MAE_norm  = mae_norm_sum  / max(w_sum, 1e-8)\n",
    "    RMSE_raw  = math.sqrt(rmse_raw_sum  / max(w_sum, 1e-8))\n",
    "    RMSE_norm = math.sqrt(rmse_norm_sum / max(w_sum, 1e-8))\n",
    "\n",
    "    return dict(\n",
    "        CRPS_raw=CRPS_raw, CRPS_norm=CRPS_norm,\n",
    "        MAE_raw=MAE_raw, RMSE_raw=RMSE_raw,\n",
    "        MAE_norm=MAE_norm, RMSE_norm=RMSE_norm,\n",
    "        K=K, n_obs_bins=int(w_sum),\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8) Training loop with periodic eval + checkpoint\n",
    "# ============================================================\n",
    "best_rmse = float('inf')\n",
    "ckpt = os.path.join(RESULT_DIR, 'best_ctx9.pt')\n",
    "\n",
    "pbar = tqdm(range(TOTAL_STEPS), desc=\"Train(ctx9)\")\n",
    "run_loss = 0.0\n",
    "it = iter(train_loader)\n",
    "\n",
    "for step in pbar:\n",
    "    try:\n",
    "        x0, msk, cond, mu, std = next(it)\n",
    "    except StopIteration:\n",
    "        it = iter(train_loader)\n",
    "        x0, msk, cond, mu, std = next(it)\n",
    "\n",
    "    x0   = x0.to(DEVICE, non_blocking=True)\n",
    "    msk  = msk.to(DEVICE, non_blocking=True)\n",
    "    cond = cond.to(DEVICE, non_blocking=True)\n",
    "\n",
    "    opt.zero_grad(set_to_none=True)\n",
    "    loss = diffusion(x0, msk, cond)\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(diffusion.parameters(), 1.0)\n",
    "    opt.step()\n",
    "    sched.step()\n",
    "\n",
    "    run_loss += loss.item()\n",
    "    if (step+1) % LOG_EVERY == 0:\n",
    "        avg = run_loss / LOG_EVERY\n",
    "        run_loss = 0.0\n",
    "        # grab LR robustly\n",
    "        curr_lr = opt.param_groups[0][\"lr\"]\n",
    "        pbar.set_postfix(loss=f\"{avg:.4f}\", lr=f\"{curr_lr:.2e}\")\n",
    "\n",
    "\n",
    "    if (step+1) % EVAL_EVERY == 0:\n",
    "        diffusion.eval()\n",
    "        with torch.inference_mode():\n",
    "            # rmse_raw, rmse_norm, nobs = eval_rmse(diffusion, test_loader) # FIXME : original eval code\n",
    "            rmse_raw, rmse_norm, nobs = eval_rmse_minibatch(diffusion, test_loader, max_batches=200)\n",
    "            # m = eval_crps_and_points(diffusion, test_loader, K=10, clip=False)  # <-- CRPS (and friends)\n",
    "        print(f\"\\n[Step {step+1}] Test RMSE_raw={rmse_raw:.3f} µg/m³ | RMSE_norm={rmse_norm:.3f} (over {nobs} bins)\")\n",
    "\n",
    "        \n",
    "        # print(f\"\\n[Step {step+1}] Test RMSE_raw={rmse_raw:.3f} µg/m³ | RMSE_norm={rmse_norm:.3f} \"\n",
    "        #       f\"(over {nobs} bins) | CRPS_raw={m['CRPS_raw']:.3f} µg/m³ (K={m['K']})\")\n",
    "        if rmse_raw < best_rmse:\n",
    "            best_rmse = rmse_raw\n",
    "            torch.save({'unet': unet.state_dict(),\n",
    "                        'diff': diffusion.state_dict(),\n",
    "                        'H': H, 'W': W}, ckpt)\n",
    "            print(f\"  >> Saved best checkpoint @ {ckpt} (RMSE_raw={best_rmse:.3f})\")\n",
    "        diffusion.train()\n",
    "\n",
    "    if (step+1) % SAVE_SAMPLES_EVERY == 0:\n",
    "        diffusion.eval()\n",
    "        with torch.inference_mode():\n",
    "            # grab a test batch, sample, and save plain grids (tanh -> [0,1] for viewing)\n",
    "            xb, mb, cb, mub, stdb = next(iter(test_loader))\n",
    "            xhat = diffusion.sample(cb.to(DEVICE)).cpu()\n",
    "            vis = (xhat + 1.0) * 0.5\n",
    "            save_image(vis, os.path.join(RESULT_DIR, f\"samples_step{step+1}.png\"), nrow=4)\n",
    "        diffusion.train()\n",
    "\n",
    "print(\"Done. Best Test RMSE_raw:\", best_rmse)\n",
    "\n",
    "# ============================================================\n",
    "# 9) Inference + overlay: GT vs Pred (only observed bins)\n",
    "# ============================================================\n",
    "def overlay_panel(test_loader, model, save_path=os.path.join(RESULT_DIR, 'ctx9_overlay.png'),\n",
    "                  back_img='./airdelhi_background.png'):\n",
    "    try:\n",
    "        back = plt.imread(back_img)\n",
    "    except:\n",
    "        back = None\n",
    "\n",
    "    import matplotlib.colors as colors\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "    cmap0 = LinearSegmentedColormap.from_list('', ['white', 'orange', 'red'])\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        xb, mb, cb, mub, stdb = next(iter(test_loader))\n",
    "        xhat = model.sample(cb.to(DEVICE), clip=False).cpu()  # tanh(z)\n",
    "        raw_hat = inv_tanh_to_raw(xhat, mub[:,None,None,None], stdb[:,None,None,None]).squeeze(1)\n",
    "        raw_gt  = inv_tanh_to_raw(xb,   mub[:,None,None,None], stdb[:,None,None,None]).squeeze(1)\n",
    "        mb      = mb.squeeze(1)\n",
    "\n",
    "    vmax = float(mub.mean() + 3*stdb.mean())\n",
    "    lon_edges = np.linspace(0,1,W+1); lat_edges = np.linspace(0,1,H+1)\n",
    "\n",
    "    B = min(8, raw_hat.size(0))\n",
    "    fig, axes = plt.subplots(2, B, figsize=(3.4*B, 6.8))\n",
    "    for i in range(B):\n",
    "        for row, arr in enumerate([raw_gt[i].numpy(), raw_hat[i].numpy()]):\n",
    "            ax = axes[row, i]\n",
    "            if back is not None: ax.imshow(back, extent=[0,1,0,1], alpha=0.6)\n",
    "            arr_plot = arr.copy()\n",
    "            arr_plot[mb[i].numpy() == 0] = np.nan  # show only observed bins\n",
    "            pm = ax.pcolormesh(lon_edges, lat_edges, arr_plot, cmap=cmap0,\n",
    "                               norm=colors.Normalize(vmin=0, vmax=vmax))\n",
    "            # draw grid\n",
    "            for y in lat_edges: ax.plot([0,1],[y,y], c='k', lw=0.1)\n",
    "            for x in lon_edges: ax.plot([x,x],[0,1], c='k', lw=0.1)\n",
    "            ax.set_axis_off()\n",
    "        axes[0, i].set_title(\"GT (obs bins)\", fontsize=11)\n",
    "        axes[1, i].set_title(\"Pred (obs bins)\", fontsize=11)\n",
    "\n",
    "    cbar = fig.colorbar(pm, ax=axes.ravel().tolist(), fraction=0.03, pad=0.02)\n",
    "    cbar.ax.tick_params(labelsize=10)\n",
    "    plt.tight_layout(); plt.savefig(save_path, dpi=140, bbox_inches='tight'); plt.close(fig)\n",
    "    print(\"Saved overlays to:\", save_path)\n",
    "\n",
    "# ---- Run an overlay on current (or best-loaded) model ----\n",
    "overlay_panel(test_loader, diffusion)\n",
    "\n",
    "# ============================================================\n",
    "# 10) Load best checkpoint & run full test-day eval again\n",
    "# ============================================================\n",
    "def load_and_eval(ckpt_path, test_loader):\n",
    "    ck = torch.load(ckpt_path, map_location=DEVICE)\n",
    "    unet = UNet(base_dim=128, dim_mults=(1,2,4), in_channels=IN_CHANNELS, image_size=(H,W)).to(DEVICE)\n",
    "    unet.load_state_dict(ck['unet'])\n",
    "    diff = GaussianDiffusion(unet, image_size=(H,W), time_steps=TIME_STEPS, loss_type='l2').to(DEVICE)\n",
    "    diff.load_state_dict(ck['diff'])\n",
    "    diff.eval()\n",
    "\n",
    "    # rmse_raw, rmse_norm, nobs = eval_rmse(diff, test_loader) # FIXME : original eval code\n",
    "    rmse_raw, rmse_norm, nobs = eval_rmse_minibatch(diff, test_loader, max_batches=200)\n",
    "    print(f\"[BEST] Test RMSE_raw={rmse_raw:.3f} µg/m³ | RMSE_norm={rmse_norm:.3f} (over {nobs} bins)\")\n",
    "    overlay_panel(test_loader, diff, save_path=os.path.join(RESULT_DIR, 'ctx9_overlay_best.png'))\n",
    "    return diff\n",
    "\n",
    "# Example (after training): \n",
    "diff_best = load_and_eval(ckpt,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fb5d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGToGrid(Dataset):\n",
    "    def __init__(self, base_dataset,):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.mean = float(self.base_dataset.mean)\n",
    "        self.std = float(self.base_dataset.std)\n",
    "\n",
    "    def TorchEEG_Grid(self, channel_list, grid_templete=TORCHEEG_2DGRID, H=11, W=11):\n",
    "        \"\"\"\n",
    "        2D Grid based on TorchEEG 2D Grid\n",
    "        input 10-10 coord channel name index \n",
    "        output is grid of channel input\n",
    "        \"\"\"\n",
    "        grid = torch.zeros(H, W, dtype=torch.float32)\n",
    "        mask = torch.zeros(H, W, dtype=torch.float32)\n",
    "        return grid, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        i,o,im,om = self.base[idx]\n",
    "\n",
    "        target_grid = None\n",
    "        target_mask = None\n",
    "        cond = None\n",
    "\n",
    "        return target_grid, target_mask, cond, self.mean, self.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200d6917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some future argparse\n",
    "\n",
    "# TUEG_1.0 path in lucy's pscratch\n",
    "# /pscratch/sd/a/ahhyun/EcoGFound/DATA/scaling_data_V2_Sep_2025/striped_EEG_lmdb/TUEG_1.0/1.0_TUEG/all_resample-500_highpass-0.3_lowpass-None.lmdb\n",
    "LMDB_DIR = \"/pscratch/sd/a/ahhyun/EcoGFound/DATA/scaling_data_V2_Sep_2025/striped_EEG_lmdb/TUEG_1.0/1.0_TUEG/all_resample-500_highpass-0.3_lowpass-None.lmdb\"\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c798205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Train and Test dataset and dataloader\n",
    "\n",
    "train_eeg = Physio_for_SOLID_from_lmdb(lmdb_dir=LMDB_DIR,\n",
    "                         maxFolds=5,\n",
    "                         seed=41,\n",
    "                         train=True,)\n",
    "test_eeg = Physio_for_SOLID_from_lmdb(lmdb_dir=LMDB_DIR,\n",
    "                         maxFolds=5,\n",
    "                         seed=41,\n",
    "                         train=False,\n",
    "                         )\n",
    "\n",
    "train_set = EEGToGrid(train_eeg)\n",
    "test_set = EEGToGrid(test_eeg)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_worker=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, num_worker=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661584b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2c0642",
   "metadata": {},
   "outputs": [],
   "source": [
    "LMDB_DIR = \"/pscratch/sd/t/tylee/Dataset/1109_Physio_500Hz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de179f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_from_lmdb(Dataset):\n",
    "    def __init__(self, data_dir, transform, return_info):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.return_info = return_info\n",
    "\n",
    "    def lmdb_to_data(self, idx):\n",
    "        self.db = lmdb.open(self.data_dir, readonly=True, lock=False, readahead=True, meminit=False)\n",
    "        key = self.keys[idx]\n",
    "        with self.db.begin(write=False) as txn:\n",
    "            pair = pickle.loads(txn.get(key.encode()))\n",
    "        data = pair['sample']\n",
    "        label = pair['label']\n",
    "        data_info = pair.get('data_info', {})\n",
    "        \n",
    "        data = to_tensor(data)\n",
    "        if self.transform is not None:\n",
    "            data = self.transform(data)\n",
    "        if self.return_info:\n",
    "            return data/100, label, data_info\n",
    "        else:\n",
    "            return data/100, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_, target_ = self.data[idx], self.target[idx]\n",
    "        in_ = torch.from_numpy(input_.astype(np.float32))\n",
    "        out_ = torch.from_numpy(target_.astype(np.float32))\n",
    "        # print(in_)\n",
    "        \n",
    "        # Normalize pm2.5 values\n",
    "        in_[..., 0] = self.normalize_z(in_[..., 0])\n",
    "        out_[..., 0] = self.normalize_z(out_[..., 0])\n",
    "        \n",
    "        in_[..., 1] = in_[..., 1] / 1440\n",
    "        out_[..., 1] = out_[..., 1] / 1440\n",
    "        \n",
    "        timegap = out_[..., 1:2][0] # get the gap between t+1 and t (ignoring t-1, and t-2)\n",
    "        \n",
    "        in_ = torch.cat([in_[..., 0:1], in_[..., 2:], in_[..., 1:2], ], dim=-1)\n",
    "        out_ = torch.cat([out_[..., 0:1], out_[..., 2:], out_[..., 1:2], ], dim=-1)\n",
    "        \n",
    "        in_[..., 1] = self.normalize(in_[..., 1], self.latmin, self.latmax)\n",
    "        out_[..., 1] = self.normalize(out_[..., 1], self.latmin, self.latmax)\n",
    "        in_[..., 2] = self.normalize(in_[..., 2], self.longmin, self.longmax)\n",
    "        out_[..., 2] = self.normalize(out_[..., 2], self.longmin, self.longmax)\n",
    "        \n",
    "        i = in_[..., 0:1]\n",
    "        im = in_[..., 1:]\n",
    "        o = out_[..., 0:1]\n",
    "        om = out_[..., 1:]\n",
    "        \n",
    "        return i, o, im, om"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c5fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing torch.dataset\n",
    "\n",
    "def xform_day(day):\n",
    "    arr = [0, 30, 61]\n",
    "    w = 0 if day <= 30 else 1 if day <= 61 else 2\n",
    "    mon = ['2020-11-', '2020-12-', '2021-01-'][w]\n",
    "    date = mon + '{:02d}'.format(day - arr[w])\n",
    "    return date\n",
    "\n",
    "\n",
    "def get_suffixes(mode):\n",
    "    suffixes = []\n",
    "    if 'C' in mode or 'A' in mode:\n",
    "        suffixes.append('train')\n",
    "    if 'D' in mode or 'B' in mode:\n",
    "        suffixes.append('test')\n",
    "    return suffixes\n",
    "\n",
    "def rename_cols(data):\n",
    "    data.rename(\n",
    "        columns={'dateTime': 'time', 'lat': 'latitude', 'long': 'longitude', 'pm2_5': 'PM25_Concentration',\n",
    "                 'pm10': 'PM10_Concentration'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "def torch1dgrid(num, bot=0, top=1):\n",
    "    arr = torch.linspace(bot, top, steps=num)\n",
    "    mesh = torch.stack([arr], dim=1)\n",
    "    return mesh.squeeze(-1)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from einops import rearrange        \n",
    "class Delhi(Dataset):\n",
    "    def __init__(\n",
    "        self, mode_t, mode_p, canada, train_days, \n",
    "        maxFolds = 5, target_fold = 0, temporal_scaling=1, spatiotemporal=1, data_dir='/pscratch/sd/d/dpark1/AirDelhi/delhi/processed', \n",
    "        seed=10, nTrainStartDay = 15, nTestStartDay = 75, nTotalDays = 91, train=True):\n",
    "        \n",
    "        self.mode_t = mode_t\n",
    "        self.mode_p = mode_p\n",
    "        self.train_days = train_days\n",
    "        self.train = train\n",
    "        self.maxFolds = maxFolds\n",
    "        self.target_fold = target_fold\n",
    "        self.temporal_scaling = temporal_scaling\n",
    "        self.spatiotemporal = spatiotemporal\n",
    "        self.data_dir = data_dir\n",
    "        self.nTestStartDay = nTestStartDay\n",
    "        self.nTrainStartDay = nTrainStartDay\n",
    "        self.nTotalDays = nTotalDays\n",
    "        \n",
    "        np.random.seed(seed)        \n",
    "        \n",
    "        self.train_suffix = get_suffixes(mode_t)\n",
    "                \n",
    "        if spatiotemporal < 0 and mode_t == 'AB' and mode_p == 'CD':\n",
    "            # Forecasting, single fold is enough\n",
    "            maxFolds = 1\n",
    "    \n",
    "        self.folds = [i for i in range(maxFolds)]\n",
    "        \n",
    "        self.data, self.target = self.proc_custom(target_fold)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_normalize_params(self, target):\n",
    "        all_signal = []\n",
    "        for a in target:\n",
    "            all_signal += list(a[..., 0])\n",
    "        self.mean, self.std = np.array(all_signal).mean(), np.array(all_signal).std()\n",
    "    \n",
    "    def get_spatial_norm_parameters(self, arr_of_days):\n",
    "        \"\"\"\"minmax normalization\"\"\"\n",
    "        latmin = 10e10\n",
    "        latmax = -10e10\n",
    "        longmin = 10e10\n",
    "        longmax = -10e10\n",
    "        for arr in arr_of_days:\n",
    "            minned = arr.min(0)\n",
    "            # print(minned[0])\n",
    "            if minned[2] < latmin:\n",
    "                latmin = minned[2]\n",
    "            if minned[3] < longmin:\n",
    "                longmin = minned[3]\n",
    "                \n",
    "            maxed = arr.max(0)\n",
    "            # print(maxed)\n",
    "            if maxed[2] > latmax:\n",
    "                latmax = maxed[2]\n",
    "            if maxed[3] > longmax:\n",
    "                longmax = maxed[3]\n",
    "        self.latmin, self.latmax, self.longmin, self.longmax =latmin, latmax, longmin, longmax\n",
    "    \n",
    "    def make_data_by_time(self, arr_of_days, t_in = 9, reverse=False, day = 0):\n",
    "        seg_by_time = []\n",
    "        uniq_times = np.unique(arr_of_days[..., 1])\n",
    "        \n",
    "        for t in uniq_times:\n",
    "            idx_ = arr_of_days[..., 1] == t\n",
    "            seg_by_time.append(arr_of_days[idx_])\n",
    "        \n",
    "        in_ = []\n",
    "        out_ = []\n",
    "        for i in range(len(seg_by_time) - t_in):\n",
    "            temp_in = []\n",
    "            for t_ in range(t_in):\n",
    "                temp_in.append(seg_by_time[i + t_])\n",
    "            \n",
    "            # normalize time to relative scale by the last one of the encoder\n",
    "            in_cand = np.copy(np.concatenate(temp_in, axis=0))\n",
    "            out_cand = np.copy(seg_by_time[i + t_in])\n",
    "            \n",
    "            last_enc_t = in_cand[..., 1][-1]\n",
    "            in_cand[..., 1] -= last_enc_t\n",
    "            out_cand[..., 1] -= last_enc_t\n",
    "            in_.append(in_cand)\n",
    "            out_.append(out_cand)\n",
    "            self.day_record.append(day)\n",
    "            \n",
    "            # reverse it\n",
    "            if reverse:\n",
    "                out_cand = np.copy(seg_by_time[i])\n",
    "                temp_in = temp_in[1:]\n",
    "                temp_in.append(seg_by_time[i + t_in])\n",
    "                in_cand = np.copy(np.concatenate(temp_in, axis=0))\n",
    "                last_enc_t = in_cand[..., 1][0]\n",
    "                in_cand[..., 1] -= last_enc_t\n",
    "                out_cand[..., 1] -= last_enc_t\n",
    "                \n",
    "                in_.append(in_cand)\n",
    "                out_.append(out_cand)\n",
    "                self.day_record.append(day)\n",
    "        \n",
    "        \n",
    "        return in_, out_\n",
    "    \n",
    "    def proc_custom(self, fold):\n",
    "        \n",
    "        self.day_record = []\n",
    "        \n",
    "        train_data = {'input':[], 'target':[]}\n",
    "        test_data = {'input':[], 'target':[]}\n",
    "        \n",
    "        for day in range(self.nTrainStartDay, self.nTestStartDay):\n",
    "            date = []\n",
    "            for i in range(self.train_days,-1,-1):\n",
    "                date.append(xform_day(day-i))\n",
    "\n",
    "            train_input,train_output,test_input,test_output = self.process_np(fold, date)\n",
    "            train_in = np.concatenate([train_output[..., np.newaxis], train_input], axis=1) # 1 days\n",
    "            train_out = np.concatenate([test_output[..., np.newaxis], test_input], axis=1) # 1 day\n",
    "            \n",
    "            seg_in, seg_out = self.make_data_by_time(train_in, day = day)\n",
    "            \n",
    "            train_data['input'] += seg_in\n",
    "            train_data['target'] += seg_out            \n",
    "        \n",
    "        \n",
    "        \n",
    "        seg_in, seg_out = self.make_data_by_time(train_out)\n",
    "        train_data['input'] += seg_in\n",
    "        train_data['target'] += seg_out\n",
    "            \n",
    "        \n",
    "        for day in range(self.nTestStartDay, self.nTotalDays+1):\n",
    "            date = []\n",
    "            for i in range(self.train_days,-1,-1):\n",
    "                date.append(xform_day(day-i))\n",
    "\n",
    "            train_input,train_output,test_input,test_output = self.process_np(fold, date)\n",
    "            test_in = np.concatenate([train_output[..., np.newaxis], train_input], axis=1) # 1 days\n",
    "            test_out = np.concatenate([test_output[..., np.newaxis], test_input], axis=1) # 1 day\n",
    "\n",
    "            seg_in, seg_out = self.make_data_by_time(test_in, reverse = False)\n",
    "            \n",
    "            test_data['input'] += seg_in\n",
    "            test_data['target'] += seg_out            \n",
    "            \n",
    "        seg_in, seg_out = self.make_data_by_time(test_out, reverse = False)\n",
    "        test_data['input'] += seg_in\n",
    "        test_data['target'] += seg_out\n",
    "\n",
    "        self.get_normalize_params(train_data['target']) \n",
    "        self.get_spatial_norm_parameters(train_data['target'])\n",
    "            \n",
    "        if self.train:\n",
    "            data = train_data['input']\n",
    "            target = train_data['target']\n",
    "            print(len(data), len(target))\n",
    "            \n",
    "        else:\n",
    "            data = test_data['input']\n",
    "            target = test_data['target']\n",
    "            print(len(data), len(target))\n",
    "\n",
    "        return data, target        \n",
    "    \n",
    "    \n",
    "\n",
    "    def process_np(self, fold, date):\n",
    "        tmStart = datetime.datetime.now()\n",
    "        train_input,train_output,test_input,test_output = self.return_data_time(fold=fold, data=date, with_scaling=True)\n",
    "        return train_input,train_output,test_input,test_output\n",
    "    \n",
    "    def return_data_time(self, fold, data, with_scaling):\n",
    "        train_input = None\n",
    "        if 'A' in self.mode_t or 'B' in self.mode_t:\n",
    "            for idx,dt in enumerate(data[:-1]):\n",
    "                for suffix in self.train_suffix:\n",
    "                    input = pd.read_csv(self.data_dir+'/'+dt+'_f'+str(fold)+'_'+suffix+'.csv')\n",
    "                    # if self.temporal_scaling:\n",
    "                    #     input.dateTime += idx * 24 * 60\n",
    "                    train_input = pd.concat((train_input, input))\n",
    "                    \n",
    "        if 'C' in self.mode_t:\n",
    "            input = pd.read_csv(self.data_dir + '/' + data[-1] + '_f' + str(fold) + '_train.csv')\n",
    "            # if self.temporal_scaling:\n",
    "            #     input.dateTime += (len(data)-1) * 24 * 60\n",
    "            train_input = pd.concat((train_input, input))\n",
    "\n",
    "        test_input = pd.read_csv(self.data_dir+'/'+data[-1]+'_f'+str(fold)+'_test.csv')\n",
    "        \n",
    "        if 'C' in self.mode_p:\n",
    "            input = pd.read_csv(self.data_dir + '/' + data[-1] + '_f' + str(fold) + '_train.csv')\n",
    "            test_input = pd.concat((input, test_input))\n",
    "            \n",
    "        # if self.temporal_scaling:\n",
    "        #     test_input.dateTime += (len(data)-1) * 24 * 60\n",
    "\n",
    "        return self.return_data_0(train_input, test_input, with_scaling)\n",
    "\n",
    "    \n",
    "    def return_data_0(self, train_input, test_input, with_scaling):\n",
    "        train_output = np.array(train_input['pm2_5'])\n",
    "        train_input = train_input[['dateTime','lat','long']]\n",
    "        test_output = np.array(test_input['pm2_5'])\n",
    "        test_input = test_input[['dateTime','lat','long']]\n",
    "\n",
    "        # if with_scaling:\n",
    "        #     scaler = MinMaxScaler().fit(train_input)\n",
    "        #     if self.temporal_scaling:\n",
    "        #         data = scaler.transform(pd.concat((train_input, test_input)))\n",
    "        #         test_input = data[len(train_input):]\n",
    "        #         train_input = data[:len(train_input)]\n",
    "        #     else:\n",
    "        #         train_input = scaler.transform(train_input)\n",
    "        #         test_input = scaler.transform(test_input)\n",
    "        return train_input,train_output,test_input,test_output\n",
    "\n",
    "    def set_target_fold(self, fold=0):\n",
    "        self.fold = fold\n",
    "        print('target fold set to {}'.format(self.fold))\n",
    "        \n",
    "    def normalize_z(self, arr):\n",
    "        return (arr - self.mean) / self.std\n",
    "    \n",
    "    def normalize(self, data, min_, max_):\n",
    "        return (data - min_) / (max_ - min_)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_, target_ = self.data[idx], self.target[idx]\n",
    "        in_ = torch.from_numpy(input_.astype(np.float32))\n",
    "        out_ = torch.from_numpy(target_.astype(np.float32))\n",
    "        # print(in_)\n",
    "        \n",
    "        # Normalize pm2.5 values\n",
    "        in_[..., 0] = self.normalize_z(in_[..., 0])\n",
    "        out_[..., 0] = self.normalize_z(out_[..., 0])\n",
    "        \n",
    "        in_[..., 1] = in_[..., 1] / 1440\n",
    "        out_[..., 1] = out_[..., 1] / 1440\n",
    "        \n",
    "        timegap = out_[..., 1:2][0] # get the gap between t+1 and t (ignoring t-1, and t-2)\n",
    "        \n",
    "        in_ = torch.cat([in_[..., 0:1], in_[..., 2:], in_[..., 1:2], ], dim=-1)\n",
    "        out_ = torch.cat([out_[..., 0:1], out_[..., 2:], out_[..., 1:2], ], dim=-1)\n",
    "        \n",
    "        in_[..., 1] = self.normalize(in_[..., 1], self.latmin, self.latmax)\n",
    "        out_[..., 1] = self.normalize(out_[..., 1], self.latmin, self.latmax)\n",
    "        in_[..., 2] = self.normalize(in_[..., 2], self.longmin, self.longmax)\n",
    "        out_[..., 2] = self.normalize(out_[..., 2], self.longmin, self.longmax)\n",
    "        \n",
    "        i = in_[..., 0:1]\n",
    "        im = in_[..., 1:]\n",
    "        o = out_[..., 0:1]\n",
    "        om = out_[..., 1:]\n",
    "        \n",
    "        return i, o, im, om"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solid_eeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
