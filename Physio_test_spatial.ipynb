{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dc9471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmdb\n",
    "import datetime\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "import scipy.io\n",
    "import pickle\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from einops import rearrange\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from cosine_annealing_warmup import CosineAnnealingWarmupRestarts\n",
    "\n",
    "import math\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d96eafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(array):\n",
    "    return torch.from_numpy(array).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a341e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    print(f'set seed {seed} is done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3389d8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "KeyT = Union[str, bytes, bytearray]\n",
    "\n",
    "_KEY_RE = re.compile(\n",
    "   r\"^S(?P<sub_id>\\d{3})R\\d{2}-\\d+$\"\n",
    ")\n",
    "\n",
    "# S012R04-21\n",
    "\n",
    "def _decode_key(k: KeyT) -> str:\n",
    "    if isinstance(k, (bytes, bytearray)):\n",
    "        return k.decode(\"utf-8\", errors=\"ignore\")\n",
    "    return k\n",
    "\n",
    "def _extract_sub_id(k: KeyT) -> str:\n",
    "    s = _decode_key(k)\n",
    "    m = _KEY_RE.match(s)\n",
    "    if m is None:\n",
    "        raise ValueError(f\"Key does not match expected patterns: {s}\")\n",
    "    return m.group(\"sub_id\")\n",
    "\n",
    "\n",
    "def train_test_split_by_fold_num(\n",
    "    fold_num: int,\n",
    "    lmdb_keys: List[KeyT],\n",
    "    maxFold: int,\n",
    "    split_by_sub: bool = True,\n",
    "    seed: int = 41\n",
    ") -> Tuple[List[KeyT], List[KeyT]]:\n",
    "    \"\"\"\n",
    "    True k-fold cross-validation split.\n",
    "\n",
    "    Args:\n",
    "        fold_num: test fold index (0 <= fold_num < maxFold)\n",
    "        lmdb_keys: LMDB key list\n",
    "        maxFold: total number of folds (k)\n",
    "        split_by_sub: True → subject-wise k-fold, False → key-wise k-fold\n",
    "\n",
    "    Returns:\n",
    "        train_key_list, test_key_list\n",
    "    \"\"\"\n",
    "    if maxFold < 2:\n",
    "        raise ValueError(\"maxFold must be >= 2.\")\n",
    "    if fold_num < 0 or fold_num >= maxFold:\n",
    "        raise ValueError(f\"fold_num must be in [0, {maxFold-1}]\")\n",
    "\n",
    "    keys = list(lmdb_keys)\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    if split_by_sub:\n",
    "        # -------- subject-wise k-fold --------\n",
    "        sub_to_keys = defaultdict(list)\n",
    "        invalid = []\n",
    "\n",
    "        for k in keys:\n",
    "            try:\n",
    "                sid = _extract_sub_id(k)\n",
    "                sub_to_keys[sid].append(k)\n",
    "            except ValueError:\n",
    "                invalid.append(_decode_key(k))\n",
    "\n",
    "        if invalid:\n",
    "            ex = \"\\n\".join(invalid[:10])\n",
    "            raise ValueError(\n",
    "                f\"Found {len(invalid)} invalid keys. Examples:\\n{ex}\"\n",
    "            )\n",
    "\n",
    "        subjects = np.array(list(sub_to_keys.keys()), dtype=object)\n",
    "        rng.shuffle(subjects)\n",
    "\n",
    "        subj_folds = np.array_split(subjects, maxFold)\n",
    "        test_subjects = set(subj_folds[fold_num].tolist())\n",
    "\n",
    "        train_keys, test_keys = [], []\n",
    "        for sid, ks in sub_to_keys.items():\n",
    "            (test_keys if sid in test_subjects else train_keys).extend(ks)\n",
    "\n",
    "        return train_keys, test_keys\n",
    "\n",
    "    else:\n",
    "        # -------- key-wise k-fold --------\n",
    "        idx = np.arange(len(keys))\n",
    "        rng.shuffle(idx)\n",
    "\n",
    "        folds = np.array_split(idx, maxFold)\n",
    "        test_idx = set(folds[fold_num].tolist())\n",
    "\n",
    "        train_keys = [keys[i] for i in idx if i not in test_idx]\n",
    "        test_keys  = [keys[i] for i in idx if i in test_idx]\n",
    "\n",
    "        return train_keys, test_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d4bec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "LMDB = '/pscratch/sd/t/tylee/Dataset/PhysioNet_200Hz_for_SOLID'\n",
    "\n",
    "DB = lmdb.open(LMDB, readonly=True, lock=False, readahead=True, meminit=False)\n",
    "with DB.begin(write=False) as txn:\n",
    "    KEYS = pickle.loads(txn.get('__keys__'.encode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "829dc72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /pscratch/sd/a/ahhyun/EcoGFound/DATA/scaling_data_V2_Sep_2025/striped_EEG_lmdb\n",
    "# 아현썜 pscratch의 데이터 경로 당장은 그냥 써도 되지만 추후 내 pscratch나 m4727 등으로 옮겨서 사용할 것\n",
    "\n",
    "class Physio_for_SOLID_from_lmdb(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            lmdb_dir: str,\n",
    "            maxfold: int,\n",
    "            targetfold: int,\n",
    "            seed: int,\n",
    "            train: bool,\n",
    "            split_by_sub: bool,\n",
    "    ):\n",
    "        random_seed(seed)\n",
    "        self.seed = seed\n",
    "        self.lmdb_dir = lmdb_dir\n",
    "        self.db = lmdb.open(lmdb_dir, readonly=True, lock=False, readahead=True, meminit=False)\n",
    "        with self.db.begin(write=False) as txn:\n",
    "            self.lmdb_keys = pickle.loads(txn.get('__keys__'.encode()))\n",
    "\n",
    "        self.train = train\n",
    "        self.split_by_sub = split_by_sub\n",
    "\n",
    "        self.maxfold = maxfold\n",
    "        self.targetfold = targetfold\n",
    "        self.data, self.target, self.data_meta, self.target_meta = self.make_data_and_target_by_fold(self.targetfold, self.lmdb_keys, \n",
    "                                                                   self.maxfold, self.split_by_sub, self.seed)\n",
    "\n",
    "    def make_data_and_target_by_fold(self, fold, lmdb_keys, maxfold, split_by_sub, seed):\n",
    "        self.record = []\n",
    "\n",
    "        train_data = {'input': [], 'target': [], 'input_meta': [], 'target_meta': []}\n",
    "        test_data  = {'input': [], 'target': [], 'input_meta': [], 'target_meta': []}\n",
    "\n",
    "        train_data_keys_in_lmdb, test_data_keys_in_lmdb = train_test_split_by_fold_num(fold, lmdb_keys, maxfold, split_by_sub, seed)\n",
    "\n",
    "\n",
    "        if self.train:\n",
    "            for train_data_key in train_data_keys_in_lmdb:\n",
    "\n",
    "                # TODO : get proper seg_in and seg_out by input idx\n",
    "                seg_in, seg_out, seg_in_meta, seg_out_meta = self.segmentation_from_idx(train_data_key, self.db)\n",
    "\n",
    "                train_data['input'] += seg_in\n",
    "                train_data['target'] += seg_out\n",
    "                train_data['input_meta'] += seg_in_meta\n",
    "                train_data['target_meta']+= seg_out_meta\n",
    "\n",
    "            return (train_data['input'], train_data['target'],\n",
    "                    train_data['input_meta'], train_data['target_meta'])\n",
    "        \n",
    "        else:\n",
    "            for test_data_key in test_data_keys_in_lmdb:\n",
    "\n",
    "                seg_in, seg_out, seg_in_meta, seg_out_meta = self.segmentation_from_idx(test_data_key, self.db)\n",
    "\n",
    "                test_data['input'] += seg_in\n",
    "                test_data['target'] += seg_out\n",
    "                test_data['input_meta']  += seg_in_meta\n",
    "                test_data['target_meta'] += seg_out_meta\n",
    "                \n",
    "            return (test_data['input'], test_data['target'],\n",
    "                    test_data['input_meta'], test_data['target_meta'])\n",
    "\n",
    "\n",
    "\n",
    "    def lmdb_get(self, env, key):\n",
    "        if isinstance(key, str):\n",
    "            key = key.encode(\"utf-8\")\n",
    "        with env.begin(write=False) as txn:\n",
    "            v = txn.get(key)\n",
    "        if v is None:\n",
    "            raise KeyError(f\"Key not found: {key}\")\n",
    "        return pickle.loads(v)\n",
    "\n",
    "    def segmentation_from_idx(self, key, lmdb_db, in_len=99, out_len=1, stride=1):\n",
    "        \"\"\"\n",
    "        eeg_data_ : (C, L)  e.g. (64, 800)\n",
    "\n",
    "        sliding:\n",
    "          input  = eeg[:, t:t+99]\n",
    "          target = eeg[:, t+99:t+100]  (1 step)\n",
    "        \"\"\"\n",
    "        sample_for_key = self.lmdb_get(lmdb_db, key)\n",
    "\n",
    "        channel_name = sample_for_key['data_info']['channel_names']  # len=C\n",
    "        eeg_data = sample_for_key['sample']                         # (C, T, Fs)\n",
    "        eeg_data_ = rearrange(eeg_data, 'c t f -> c (t f)')         # (C, L)\n",
    "        eeg_data_ = torch.from_numpy(eeg_data_).to(torch.float32)\n",
    "\n",
    "        C, L = eeg_data_.shape\n",
    "        total_needed = in_len + out_len\n",
    "\n",
    "        if L < total_needed:\n",
    "            return [], [], [], []\n",
    "\n",
    "        seg_in_list = []\n",
    "        seg_out_list = []\n",
    "        seg_in_meta_list = []\n",
    "        seg_out_meta_list = []\n",
    "\n",
    "        for t in range(0, L - total_needed + 1, stride):\n",
    "            x = eeg_data_[:, t : t + in_len]                         # (C, 99)\n",
    "            y = eeg_data_[:, t + in_len : t + in_len + out_len]      # (C, 1)\n",
    "\n",
    "            seg_in_list.append(x)\n",
    "            seg_out_list.append(y)\n",
    "\n",
    "            seg_in_meta_list.append(channel_name)\n",
    "            seg_out_meta_list.append(channel_name)\n",
    "\n",
    "        return seg_in_list, seg_out_list, seg_in_meta_list, seg_out_meta_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        i  = self.data[idx]\n",
    "        o  = self.target[idx]\n",
    "        im = self.data_meta[idx]\n",
    "        om = self.target_meta[idx]\n",
    "        return i, o, im, om"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40281c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmdb, pickle\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Physio_1sec_raw_for_SOLID_from_lmdb(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            lmdb_dir: str,\n",
    "            maxfold: int,\n",
    "            targetfold: int,\n",
    "            seed: int,\n",
    "            train: bool,\n",
    "            split_by_sub: bool,\n",
    "            seg_len_sec: int = 1,\n",
    "            stride_sec: int = 1,\n",
    "    ):\n",
    "        random_seed(seed)\n",
    "        self.seed = seed\n",
    "        self.lmdb_dir = lmdb_dir\n",
    "        self.db = lmdb.open(lmdb_dir, readonly=True, lock=False, readahead=True, meminit=False)\n",
    "        with self.db.begin(write=False) as txn:\n",
    "            self.lmdb_keys = pickle.loads(txn.get('__keys__'.encode()))\n",
    "\n",
    "        self.train = train\n",
    "        self.split_by_sub = split_by_sub\n",
    "\n",
    "        self.maxfold = maxfold\n",
    "        self.targetfold = targetfold\n",
    "\n",
    "        self.seg_len_sec = seg_len_sec\n",
    "        self.stride_sec = stride_sec\n",
    "\n",
    "        self.data, self.data_meta = self.make_segments_by_fold(\n",
    "            self.targetfold, self.lmdb_keys, self.maxfold, self.split_by_sub, self.seed\n",
    "        )\n",
    "\n",
    "    def make_segments_by_fold(self, fold, lmdb_keys, maxfold, split_by_sub, seed):\n",
    "        train_keys, test_keys = train_test_split_by_fold_num(\n",
    "            fold, lmdb_keys, maxfold, split_by_sub, seed\n",
    "        )\n",
    "\n",
    "        use_keys = train_keys if self.train else test_keys\n",
    "\n",
    "        all_segs = []\n",
    "        all_meta = []\n",
    "\n",
    "        for key in use_keys:\n",
    "            seg_list, meta_list = self.segment_1sec_from_key(\n",
    "                key, self.db,\n",
    "                seg_len_sec=self.seg_len_sec,\n",
    "                stride_sec=self.stride_sec\n",
    "            )\n",
    "            all_segs += seg_list\n",
    "            all_meta += meta_list\n",
    "\n",
    "        return all_segs, all_meta\n",
    "\n",
    "    def lmdb_get(self, env, key):\n",
    "        if isinstance(key, str):\n",
    "            key = key.encode(\"utf-8\")\n",
    "        with env.begin(write=False) as txn:\n",
    "            v = txn.get(key)\n",
    "        if v is None:\n",
    "            raise KeyError(f\"Key not found: {key}\")\n",
    "        return pickle.loads(v)\n",
    "\n",
    "    def segment_1sec_from_key(self, key, lmdb_db, seg_len_sec=1, stride_sec=1):\n",
    "        \"\"\"\n",
    "        sample_for_key['sample'] shape: (C, T, Fs)\n",
    "          - 여기서 T는 '초 단위 프레임 수'이고\n",
    "          - Fs는 1초 내 샘플 수(예: 200)\n",
    "\n",
    "        seg_len_sec=1이면:\n",
    "          x = eeg[:, t, :] -> (C, Fs)\n",
    "\n",
    "        seg_len_sec>1이면:\n",
    "          x = eeg[:, t:t+seg_len_sec, :] -> (C, seg_len_sec, Fs) -> flatten -> (C, seg_len_sec*Fs)\n",
    "        \"\"\"\n",
    "        sample_for_key = self.lmdb_get(lmdb_db, key)\n",
    "\n",
    "        channel_name = sample_for_key['data_info']['channel_names']  # len=C\n",
    "        eeg = sample_for_key['sample']  # (C, T, Fs), numpy\n",
    "\n",
    "        if isinstance(eeg, torch.Tensor):\n",
    "            eeg_t = eeg.float()\n",
    "        else:\n",
    "            eeg_t = torch.from_numpy(eeg).to(torch.float32)\n",
    "\n",
    "        C, T, Fs = eeg_t.shape\n",
    "\n",
    "        if T < seg_len_sec:\n",
    "            return [], []\n",
    "\n",
    "        seg_list = []\n",
    "        meta_list = []\n",
    "\n",
    "        for t in range(0, T - seg_len_sec + 1, stride_sec):\n",
    "            x = eeg_t[:, t:t+seg_len_sec, :]          # (C, seg_len_sec, Fs)\n",
    "            x = x.reshape(C, seg_len_sec * Fs)        # (C, seg_len_sec*Fs)  -> seg_len_sec=1이면 (C, Fs)\n",
    "\n",
    "            seg_list.append(x)\n",
    "            meta_list.append(channel_name)\n",
    "\n",
    "        return seg_list, meta_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x  = self.data[idx]        # (C, 200) if seg_len_sec=1 and Fs=200\n",
    "        xm = self.data_meta[idx]   # channel names\n",
    "        return x, xm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe198315",
   "metadata": {},
   "outputs": [],
   "source": [
    "TORCHEEG_2DGRID = [\n",
    "    ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-'],\n",
    "    ['-', '-', '-', '-', 'FP1', 'FPZ', 'FP2', '-', '-', '-', '-'],\n",
    "    ['-', '-', 'AF7', '-', 'AF3', 'AFZ', 'AF4', '-', 'AF8', '-', '-'],\n",
    "    ['F9', 'F7', 'F5', 'F3', 'F1', 'FZ', 'F2', 'F4', 'F6', 'F8', 'F10'],\n",
    "    ['FT9', 'FT7', 'FC5', 'FC3', 'FC1', 'FCZ', 'FC2', 'FC4', 'FC6', 'FT8', 'FT10'], \n",
    "    ['T9', 'T7', 'C5', 'C3', 'C1', 'CZ', 'C2', 'C4', 'C6', 'T8', 'T10'],\n",
    "    ['TP9', 'TP7', 'CP5', 'CP3', 'CP1', 'CPZ', 'CP2', 'CP4', 'CP6', 'TP8', 'TP10'], \n",
    "    ['P9', 'P7', 'P5', 'P3', 'P1', 'PZ', 'P2', 'P4', 'P6', 'P8', 'P10'],\n",
    "    ['-', '-', 'PO7', 'PO5', 'PO3', 'POZ', 'PO4', 'PO6', 'PO8', '-', '-'],\n",
    "    ['-', '-', '-', 'CB1', 'O1', 'OZ', 'O2', 'CB2', '-', '-', '-'],\n",
    "    ['-', '-', '-', '-', '-', 'IZ', '-', '-', '-', '-', '-']\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b846b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_channel_to_rc(grid_2d):\n",
    "    ch2rc = {}\n",
    "    H = len(grid_2d)\n",
    "    W = len(grid_2d[0])\n",
    "    for r in range(H):\n",
    "        for c in range(W):\n",
    "            ch = grid_2d[r][c]\n",
    "            if ch != '-' and ch is not None:\n",
    "                ch2rc[str(ch).strip().upper()] = (r, c)\n",
    "    return ch2rc, H, W\n",
    "\n",
    "CHANNEL_TO_RC, H, W = build_channel_to_rc(TORCHEEG_2DGRID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1333ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splat_eeg_grid(eeg_cl, channel_names, channel_to_rc=CHANNEL_TO_RC, H=H, W=W):\n",
    "    \"\"\"\n",
    "    eeg_cl: (C, L) torch.Tensor (권장)\n",
    "    channel_names: list[str] len=C\n",
    "    returns:\n",
    "      grid: (L, H, W)\n",
    "      mask: (H, W)\n",
    "    \"\"\"\n",
    "    if not torch.is_tensor(eeg_cl):\n",
    "        eeg_cl = torch.as_tensor(eeg_cl)\n",
    "\n",
    "    assert eeg_cl.dim() == 2, f\"Expected (C,L), got {tuple(eeg_cl.shape)}\"\n",
    "    C, L = eeg_cl.shape\n",
    "    device = eeg_cl.device\n",
    "\n",
    "    grid = torch.zeros((L, H, W), dtype=eeg_cl.dtype, device=device)\n",
    "    cnt  = torch.zeros((H, W), dtype=torch.float32, device=device)\n",
    "\n",
    "    for ci in range(C):\n",
    "        ch = str(channel_names[ci]).strip().upper()\n",
    "        if ch in channel_to_rc:\n",
    "            r, c = channel_to_rc[ch]\n",
    "            grid[:, r, c] += eeg_cl[ci, :]\n",
    "            cnt[r, c] += 1.0\n",
    "\n",
    "    mask = (cnt > 0).float()\n",
    "    grid = torch.where(cnt > 0, grid / torch.clamp(cnt, min=1.0), grid)\n",
    "    return grid, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57c7cee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGToGridCtx9_1sec(Dataset):\n",
    "    \"\"\"\n",
    "    NEW VERSION for 1-sec raw base dataset.\n",
    "\n",
    "    base[idx] -> (x, xm)\n",
    "      x  : (C, L)  (torch or numpy)  e.g. (64, 200)\n",
    "      xm : channel list (len=C)\n",
    "\n",
    "    return:\n",
    "      x0        : (L, H, W)   full target grid in tanh space (optional)\n",
    "      loss_mask : (1, H, W)   1=supervise bins (typically UNOBSERVED electrode bins)\n",
    "      cond      : (L+3, H, W) = [lat_map(1), lon_map(1), obs_grid(L), obs_mask(1)]\n",
    "      mean, std\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_dataset,\n",
    "        squash_tanh: bool = True,\n",
    "        channel_to_rc=CHANNEL_TO_RC,\n",
    "        keep_ratio: float = 0.9,          # fraction of electrode bins observed\n",
    "        seed: int = 0,\n",
    "        loss_mode: str = 'all' # True면 (1-obs)에서만 loss\n",
    "    ):\n",
    "        self.base = base_dataset\n",
    "        self.squash = squash_tanh\n",
    "        self.channel_to_rc = channel_to_rc\n",
    "        self.keep_ratio = keep_ratio\n",
    "        self.seed = seed\n",
    "        self.loss_mode = loss_mode\n",
    "\n",
    "        self.mean = float(getattr(self.base, \"mean\", 0.0))\n",
    "        self.std  = float(getattr(self.base, \"std\",  1.0))\n",
    "\n",
    "        lat = torch.linspace(0, 1, H).unsqueeze(1).repeat(1, W)\n",
    "        lon = torch.linspace(0, 1, W).unsqueeze(0).repeat(H, 1)\n",
    "        self.lat_map = lat\n",
    "        self.lon_map = lon\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base)\n",
    "\n",
    "    def _sample_obs_mask(self, tgt_mask_hw: torch.Tensor, idx: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        tgt_mask_hw: (H,W)  1 where electrode exists\n",
    "        returns obs_mask_hw: (H,W) subset of tgt_mask_hw set to 1\n",
    "        \"\"\"\n",
    "        g = torch.Generator(device=tgt_mask_hw.device)\n",
    "        g.manual_seed(self.seed + idx)\n",
    "\n",
    "        valid = torch.nonzero(tgt_mask_hw > 0.5, as_tuple=False)  # (N,2)\n",
    "        N = valid.shape[0]\n",
    "        if N == 0:\n",
    "            return torch.zeros_like(tgt_mask_hw)\n",
    "\n",
    "        k = max(1, int(round(self.keep_ratio * N)))\n",
    "        perm = torch.randperm(N, generator=g, device=tgt_mask_hw.device)\n",
    "        chosen = valid[perm[:k]]\n",
    "\n",
    "        obs = torch.zeros_like(tgt_mask_hw)\n",
    "        obs[chosen[:, 0], chosen[:, 1]] = 1.0\n",
    "        return obs\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # base: (C,L), channel_names\n",
    "        x, xm = self.base[idx]\n",
    "\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.as_tensor(x, dtype=torch.float32)\n",
    "        else:\n",
    "            x = x.to(torch.float32)\n",
    "\n",
    "        # ---- full target grid/mask ----\n",
    "        # grid: (L,H,W), mask: (H,W)\n",
    "        full_grid, tgt_mask_hw = splat_eeg_grid(\n",
    "            x, xm, channel_to_rc=self.channel_to_rc, H=H, W=W\n",
    "        )\n",
    "\n",
    "        # (optional) squash to tanh space\n",
    "        x0 = torch.tanh(full_grid) if self.squash else full_grid  # (L,H,W)\n",
    "\n",
    "        # ---- observed subset mask (spatial only) ----\n",
    "        obs_mask_hw = self._sample_obs_mask(tgt_mask_hw, idx)     # (H,W)\n",
    "\n",
    "        # ---- observed input grid ----\n",
    "        obs_grid = x0 * obs_mask_hw.unsqueeze(0)                  # (L,H,W)\n",
    "\n",
    "        # ---- cond ----\n",
    "        cond = torch.cat([\n",
    "            self.lat_map.unsqueeze(0),            # (1,H,W)\n",
    "            self.lon_map.unsqueeze(0),            # (1,H,W)\n",
    "            obs_grid,                             # (L,H,W) # FIXME : 시간축 이거 필요 없을지도? 뺴고 한 번 넣고 한 번 해보자\n",
    "            obs_mask_hw.unsqueeze(0),             # (1,H,W)\n",
    "        ], dim=0)                                 # (L+3,H,W)\n",
    "\n",
    "        # ---- loss mask: where to supervise ----\n",
    "        # electrode bins only (tgt_mask_hw) + (unobserved OR observed)\n",
    "        if self.loss_mode == 'all':\n",
    "            loss_mask_hw = tgt_mask_hw      # (H,W)\n",
    "        elif self.loss_mode == 'obs':\n",
    "            loss_mask_hw = obs_mask_hw * tgt_mask_hw            # (H,W)\n",
    "        elif self.loss_mode == \"unobs\":\n",
    "            loss_mask_hw = (1.0 - obs_mask_hw) * tgt_mask_hw              # (H,W)\n",
    "        else :\n",
    "            raise ValueError('loss_mode is weird')\n",
    "\n",
    "        return x0, loss_mask_hw.unsqueeze(0), cond, self.mean, self.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5489d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "RESULT_DIR = '/pscratch/sd/t/tylee/SOLID_EEG_RESULT/small_check_1220'\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "SEED = 41\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "LR = 2e-4\n",
    "TIME_STEPS = 1000                  # diffusion T\n",
    "TOTAL_STEPS = 100_000\n",
    "LOG_EVERY  = 200\n",
    "EVAL_EVERY = 1000\n",
    "SAVE_SAMPLES_EVERY = 1000\n",
    "BG_WEIGHT = 0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abb0e7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set seed 41 is done\n",
      "set seed 41 is done\n"
     ]
    }
   ],
   "source": [
    "sample_train_dataset_1sec = Physio_1sec_raw_for_SOLID_from_lmdb(lmdb_dir='/pscratch/sd/t/tylee/Dataset/PhysioNet_200Hz_for_SOLID',\n",
    "                                                     maxfold=5,\n",
    "                                                     targetfold=0,\n",
    "                                                     seed=SEED,\n",
    "                                                     train=True,\n",
    "                                                     split_by_sub=True)\n",
    "\n",
    "sample_test_dataset_1sec = Physio_1sec_raw_for_SOLID_from_lmdb(lmdb_dir='/pscratch/sd/t/tylee/Dataset/PhysioNet_200Hz_for_SOLID',\n",
    "                                                     maxfold=5,\n",
    "                                                     targetfold=0,\n",
    "                                                     seed=SEED,\n",
    "                                                     train=False,\n",
    "                                                     split_by_sub=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f2de207",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grid_dataset = EEGToGridCtx9_1sec(base_dataset=sample_train_dataset_1sec, \n",
    "                                        squash_tanh=True, # TODO : tanh is bset option??\n",
    "                                        channel_to_rc=CHANNEL_TO_RC,\n",
    "                                        keep_ratio=0.9, # TODO : sparsity option should be added\n",
    "                                        seed=SEED,\n",
    "                                        loss_mode='all')\n",
    "\n",
    "test_grid_dataset = EEGToGridCtx9_1sec(base_dataset=sample_test_dataset_1sec, \n",
    "                                        squash_tanh=True,\n",
    "                                        channel_to_rc=CHANNEL_TO_RC,\n",
    "                                        keep_ratio=0.9,\n",
    "                                        seed=SEED,\n",
    "                                        loss_mode='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89d137e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grid_dataset_f = EEGToGridCtx9_1sec(base_dataset=sample_train_dataset_1sec, \n",
    "                                        squash_tanh=False, # TODO : tanh is bset option??\n",
    "                                        channel_to_rc=CHANNEL_TO_RC,\n",
    "                                        keep_ratio=0.9, # TODO : sparsity option should be added\n",
    "                                        seed=SEED,\n",
    "                                        loss_mode='all')\n",
    "\n",
    "test_grid_dataset_f = EEGToGridCtx9_1sec(base_dataset=sample_test_dataset_1sec, \n",
    "                                        squash_tanh=False,\n",
    "                                        channel_to_rc=CHANNEL_TO_RC,\n",
    "                                        keep_ratio=0.9,\n",
    "                                        seed=SEED,\n",
    "                                        loss_mode='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "028bfc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, loss_mask, cond, mean, std = train_grid_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31f6bcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_f, loss_mask_f, cond_f, _, _ = train_grid_dataset_f[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6025a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_stats(x, name=\"tensor\"):\n",
    "    # x: torch.Tensor\n",
    "    x_det = x.detach()\n",
    "\n",
    "    print(f\"[{name}]\")\n",
    "    print(f\"  shape: {tuple(x_det.shape)}\")\n",
    "    print(f\"  dtype: {x_det.dtype}\")\n",
    "    print(f\"  device: {x_det.device}\")\n",
    "    print(f\"  min:   {x_det.min().item():.6f}\")\n",
    "    print(f\"  max:   {x_det.max().item():.6f}\")\n",
    "    print(f\"  mean:  {x_det.mean().item():.6f}\")\n",
    "    print(f\"  std:   {x_det.std().item():.6f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87dce2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "  shape: (200, 11, 11)\n",
      "  dtype: torch.float32\n",
      "  device: cpu\n",
      "  min:   -151.059052\n",
      "  max:   147.672974\n",
      "  mean:  0.000000\n",
      "  std:   9.407033\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensor_stats(x0_f, \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7147cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "  shape: (200, 11, 11)\n",
      "  dtype: torch.float32\n",
      "  device: cpu\n",
      "  min:   -145.334702\n",
      "  max:   236.513153\n",
      "  mean:  -0.000000\n",
      "  std:   15.309644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensor_stats(x0_f, \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48690f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_grid_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_grid_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9befbb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 200])\n"
     ]
    }
   ],
   "source": [
    "data0, channel_list0 = sample_train_dataset_1sec[0]\n",
    "\n",
    "print(data0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "57ac9dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, loss_mask, cond, mean, std = train_grid_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18b61dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  1.0000,  1.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  1.0000,  1.0000,  0.0000,\n",
       "          1.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000, -0.8645, -0.3511,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
       "          1.0000,  1.0000,  0.0000],\n",
       "        [ 0.0000,  1.0000, -1.0000, -0.8793, -0.6298,  0.6734,  0.9506, -0.9960,\n",
       "         -0.8581,  1.0000,  0.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -0.9978,  1.0000, -1.0000],\n",
       "        [ 0.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9993, -1.0000, -0.9977,\n",
       "         -0.2206,  0.9993,  0.0000],\n",
       "        [ 0.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9970,  1.0000,\n",
       "          0.9990,  0.9993,  0.0000],\n",
       "        [ 0.0000,  0.0000, -1.0000,  0.0000, -1.0000, -1.0000,  1.0000,  0.0000,\n",
       "          1.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000, -1.0000,  0.7870,  1.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.3675,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0[0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1aff129e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0.],\n",
       "         [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "         [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "         [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "         [0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ba6b1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  1.0000,  1.0000,  0.0000,\n",
       "          1.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000, -0.8645, -0.3511,  1.0000,  1.0000,  1.0000,  0.0000,  1.0000,\n",
       "          1.0000,  1.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000, -1.0000, -0.8793, -0.6298,  0.6734,  0.9506, -0.9960,\n",
       "         -0.8581,  1.0000,  0.0000],\n",
       "        [-0.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         -0.9978,  0.0000, -1.0000],\n",
       "        [ 0.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9993, -1.0000, -0.9977,\n",
       "         -0.2206,  0.9993,  0.0000],\n",
       "        [ 0.0000, -1.0000, -1.0000, -1.0000, -0.0000, -1.0000, -0.9970,  1.0000,\n",
       "          0.9990,  0.9993,  0.0000],\n",
       "        [ 0.0000,  0.0000, -1.0000,  0.0000, -1.0000, -1.0000,  1.0000,  0.0000,\n",
       "          1.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000, -1.0000,  0.7870,  1.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.3675,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond[2, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e8a41553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0.],\n",
       "        [0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.],\n",
       "        [0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
       "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.],\n",
       "        [0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond[-1, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e17f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31332\n",
      "8016\n"
     ]
    }
   ],
   "source": [
    "# Model implementation from Kevin\n",
    "print(len(train_grid_dataset))\n",
    "print(len(test_grid_dataset))\n",
    "\n",
    "# ============================================================\n",
    "# 3) UNet (no attention; rectangular-friendly)\n",
    "# ============================================================\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, dim_out=None, time_emb_dim=None, dropout=0.0, groups=32):\n",
    "        super().__init__()\n",
    "        dim_out = dim if dim_out is None else dim_out\n",
    "        self.mlp = nn.Sequential(nn.SiLU(), nn.Linear(time_emb_dim, dim_out)) if time_emb_dim else None\n",
    "        self.norm1 = nn.GroupNorm(groups, dim);     self.conv1 = nn.Conv2d(dim, dim_out, 3, padding=1)\n",
    "        self.norm2 = nn.GroupNorm(groups, dim_out); self.conv2 = nn.Conv2d(dim_out, dim_out, 3, padding=1)\n",
    "        self.dropout = nn.Dropout(dropout) if dropout else nn.Identity()\n",
    "        self.act = nn.SiLU()\n",
    "        self.res = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
    "    def forward(self, x, t_emb=None):\n",
    "        h = self.conv1(self.act(self.norm1(x)))\n",
    "        if self.mlp is not None and t_emb is not None:\n",
    "            h = h + self.mlp(t_emb)[..., None, None]\n",
    "        h = self.conv2(self.dropout(self.act(self.norm2(h))))\n",
    "        return h + self.res(x)\n",
    "\n",
    "\n",
    "class SinusoidalTimeEmbedding(nn.Module):\n",
    "    def __init__(self, base_dim):\n",
    "        super().__init__()\n",
    "        self.out_dim = base_dim\n",
    "    def forward(self, t):  # t: (B,)\n",
    "        # classic transformer-style PE on scalar t\n",
    "        half = self.out_dim // 2\n",
    "        device = t.device\n",
    "        freqs = torch.exp(torch.arange(half, device=device).float()\n",
    "                          * -(math.log(10000.0) / max(1, half-1)))\n",
    "        ang = t.float().unsqueeze(1) * freqs.unsqueeze(0)  # (B, half)\n",
    "        emb = torch.cat([torch.sin(ang), torch.cos(ang)], dim=1)  # (B, 2*half)\n",
    "        if emb.shape[1] < self.out_dim:\n",
    "            emb = F.pad(emb, (0, self.out_dim - emb.shape[1]))\n",
    "        return emb\n",
    "\n",
    "class TimeMLP(nn.Module):\n",
    "    def __init__(self, base_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1, base_dim*4), nn.SiLU(),\n",
    "            nn.Linear(base_dim*4, base_dim*4)\n",
    "        )\n",
    "    def forward(self, t):  # (B,)\n",
    "        return self.net(t[:,None].float())\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, base_dim=128, dim_mults=(1,2,4),\n",
    "                 in_channels=1+20, image_size=(H,W), dropout=0.0, groups=32):\n",
    "        super().__init__()\n",
    "        self.image_h, self.image_w = image_size\n",
    "        self.time_dim = base_dim * 4\n",
    "\n",
    "        # self.time_pe  = SinusoidalTimeEmbedding(base_dim)\n",
    "        # self.time_mlp = nn.Sequential(\n",
    "        #     nn.Linear(base_dim, self.time_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.time_dim, self.time_dim)\n",
    "        # )\n",
    "        self.time_mlp = TimeMLP(base_dim)\n",
    "        self.init = nn.Conv2d(in_channels, base_dim, 3, padding=1)\n",
    "\n",
    "        self.downs = nn.ModuleList()\n",
    "        in_ch = base_dim\n",
    "        skip_channels = []\n",
    "        for li, m in enumerate(dim_mults):\n",
    "            out_ch = base_dim * m\n",
    "            rb1 = ResnetBlock(in_ch, out_ch, self.time_dim, dropout, groups); self.downs.append(rb1); in_ch = out_ch; skip_channels.append(in_ch)\n",
    "            rb2 = ResnetBlock(in_ch, out_ch, self.time_dim, dropout, groups); self.downs.append(rb2); in_ch = out_ch; skip_channels.append(in_ch)\n",
    "            if li != len(dim_mults) - 1:\n",
    "                self.downs.append(nn.Conv2d(in_ch, in_ch, 3, stride=2, padding=1))\n",
    "\n",
    "        self.mid1 = ResnetBlock(in_ch, in_ch, self.time_dim, dropout, groups)\n",
    "        self.mid2 = ResnetBlock(in_ch, in_ch, self.time_dim, dropout, groups)\n",
    "\n",
    "        self.ups, self.kinds = nn.ModuleList(), []\n",
    "        sc = skip_channels.copy()\n",
    "        for li, m in enumerate(reversed(dim_mults)):\n",
    "            out_ch = base_dim * m\n",
    "            for _ in range(2):\n",
    "                skip_ch = sc.pop()\n",
    "                self.ups.append(ResnetBlock(in_ch + skip_ch, out_ch, self.time_dim, dropout, groups)); self.kinds.append('res')\n",
    "                in_ch = out_ch\n",
    "            if li != len(dim_mults) - 1:\n",
    "                self.ups.append(nn.Upsample(scale_factor=2, mode='nearest')); self.kinds.append('up')\n",
    "                self.ups.append(nn.Conv2d(in_ch, in_ch, 3, padding=1));       self.kinds.append('conv')\n",
    "\n",
    "        self.final = nn.Sequential(nn.GroupNorm(groups, in_ch), nn.SiLU(), nn.Conv2d(in_ch, 200, 3, padding=1)) # output dim to 200 from 1\n",
    "\n",
    "    def forward(self, x_cat, t):\n",
    "        # t_emb = self.time_mlp(self.time_pe(t))\n",
    "        t_emb = self.time_mlp(t)\n",
    "        skips, h = [], self.init(x_cat)\n",
    "        for layer in self.downs:\n",
    "            if isinstance(layer, ResnetBlock):\n",
    "                h = layer(h, t_emb); skips.append(h)\n",
    "            else:\n",
    "                h = layer(h)\n",
    "        h = self.mid1(h, t_emb); h = self.mid2(h, t_emb)\n",
    "        for kind, layer in zip(self.kinds, self.ups):\n",
    "            if kind == 'res':\n",
    "                s = skips.pop()\n",
    "                if s.shape[-2:] != h.shape[-2:]:\n",
    "                    s = F.interpolate(s, size=h.shape[-2:], mode='nearest')\n",
    "                h = layer(torch.cat([h, s], dim=1), t_emb)\n",
    "            elif kind == 'up':\n",
    "                h = layer(h)\n",
    "            else:\n",
    "                h = layer(h)\n",
    "        if h.shape[-2:] != (self.image_h, self.image_w):\n",
    "            h = F.interpolate(h, size=(self.image_h, self.image_w), mode='nearest')\n",
    "        return self.final(h)\n",
    "\n",
    "# ============================================================\n",
    "# 4) Diffusion core — noise only target channel; cond is clean\n",
    "# ============================================================\n",
    "class GaussianDiffusion(nn.Module):\n",
    "    def __init__(self, unet, image_size=(H,W), time_steps=TIME_STEPS, loss_type='l2'):\n",
    "        super().__init__()\n",
    "        self.unet = unet\n",
    "        self.H, self.W = image_size\n",
    "        self.T = time_steps\n",
    "        self.loss_type = loss_type\n",
    "\n",
    "        beta  = self.linear_beta_schedule(time_steps)\n",
    "        alpha = 1. - beta\n",
    "        abar  = torch.cumprod(alpha, dim=0)\n",
    "        abar_prev = F.pad(abar[:-1], (1,0), value=1.)\n",
    "\n",
    "        self.register_buffer('beta', beta)\n",
    "        self.register_buffer('alpha', alpha)\n",
    "        self.register_buffer('alpha_bar', abar)\n",
    "        self.register_buffer('alpha_bar_prev', abar_prev)\n",
    "        self.register_buffer('sqrt_alpha_bar', torch.sqrt(abar))\n",
    "        self.register_buffer('sqrt_one_minus_alpha_bar', torch.sqrt(1 - abar))\n",
    "        self.register_buffer('sqrt_recip_alpha_bar', torch.sqrt(1. / abar))\n",
    "        self.register_buffer('sqrt_recip_alpha_bar_min_1', torch.sqrt(1. / abar - 1))\n",
    "        self.register_buffer('sqrt_recip_alpha', torch.sqrt(1. / alpha))\n",
    "        self.register_buffer('beta_over_sqrt_one_minus_alpha_bar', beta / torch.sqrt(1. - abar))\n",
    "\n",
    "    def linear_beta_schedule(self, T):\n",
    "        scale = 1000 / T\n",
    "        return torch.linspace(scale*1e-4, scale*2e-2, T, dtype=torch.float32)\n",
    "\n",
    "    def q_sample(self, x0, t, noise):\n",
    "        return self.sqrt_alpha_bar[t][:,None,None,None] * x0 + \\\n",
    "               self.sqrt_one_minus_alpha_bar[t][:,None,None,None] * noise\n",
    "\n",
    "    def forward(self, x0, mask, cond):\n",
    "        \"\"\"\n",
    "        x0:   (B,1,H,W) in tanh(z) space\n",
    "        mask: (B,1,H,W)  (1=observed bin in target; 0=unobserved)\n",
    "        cond: (B,20,H,W) = [lat, lon, past_grids(9), past_masks(9)]\n",
    "        \"\"\"\n",
    "        b = x0.size(0)\n",
    "        t = torch.randint(0, self.T, (b,), device=x0.device).long()\n",
    "\n",
    "        noise = torch.randn_like(x0)\n",
    "        x_t   = self.q_sample(x0, t, noise)\n",
    "        x_cat = torch.cat([x_t, cond], dim=1)  # noised target + clean cond\n",
    "\n",
    "        pred = self.unet(x_cat, t)  # predict noise on target channel\n",
    "\n",
    "        if self.loss_type == 'l1':\n",
    "            raw = F.l1_loss(noise, pred, reduction='none')\n",
    "        elif self.loss_type == 'l2':\n",
    "            raw = F.mse_loss(noise, pred, reduction='none')\n",
    "        else:\n",
    "            raw = F.smooth_l1_loss(noise, pred, reduction='none')\n",
    "\n",
    "        w = mask + BG_WEIGHT  # supervise observed bins + tiny everywhere\n",
    "        return (raw * w).sum() / (w.sum() + 1e-8)\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def p_sample(self, xt, cond, t, clip=True):\n",
    "        bt = torch.full((xt.shape[0],), t, device=xt.device, dtype=torch.long)\n",
    "        x_cat = torch.cat([xt, cond], dim=1)\n",
    "        pred_noise = self.unet(x_cat, bt)\n",
    "\n",
    "        def bcast(x): return x.view(-1,1,1,1)\n",
    "        if clip:\n",
    "            x0 = bcast(self.sqrt_recip_alpha_bar[bt]) * xt - bcast(self.sqrt_recip_alpha_bar_min_1[bt]) * pred_noise\n",
    "            x0 = x0.clamp(-1., 1.)\n",
    "            c1 = self.beta[bt] * torch.sqrt(self.alpha_bar_prev[bt]) / (1. - self.alpha_bar[bt])\n",
    "            c2 = torch.sqrt(self.alpha[bt]) * (1. - self.alpha_bar_prev[bt]) / (1. - self.alpha[bt])\n",
    "            mean = bcast(c1) * x0 + bcast(c2) * xt\n",
    "        else:\n",
    "            mean = bcast(self.sqrt_recip_alpha[bt]) * (xt - bcast(self.beta_over_sqrt_one_minus_alpha_bar[bt]) * pred_noise)\n",
    "        var = self.beta[bt] * ((1. - self.alpha_bar_prev[bt]) / (1. - self.alpha_bar[bt]))\n",
    "        noise = torch.randn_like(xt) if t > 0 else 0.\n",
    "        return mean + torch.sqrt(bcast(var)) * noise\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def sample(self, cond, clip=False):  # clip=False often gives crisper fields\n",
    "        b = cond.size(0)\n",
    "        x = torch.randn((b,200,self.H,self.W), device=cond.device)\n",
    "        for t in reversed(range(self.T)):\n",
    "            x = self.p_sample(x, cond, t, clip=clip)\n",
    "        return x.clamp(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16c60d69",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 5.81 MiB is free. Including non-PyTorch memory, this process has 1.42 GiB memory in use. Process 2236692 has 37.94 GiB memory in use. Of the allocated memory 922.02 MiB is allocated by PyTorch, and 19.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 6) Build model + diffusion + optimizer\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[1;32m      4\u001b[0m IN_CHANNELS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m   \u001b[38;5;66;03m# target(noised) + lat/lon + 9 past grids + 9 past masks = 21\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m unet \u001b[38;5;241m=\u001b[39m \u001b[43mUNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_mults\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mIN_CHANNELS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m diffusion \u001b[38;5;241m=\u001b[39m GaussianDiffusion(unet, image_size\u001b[38;5;241m=\u001b[39m(H,W), time_steps\u001b[38;5;241m=\u001b[39mTIME_STEPS, loss_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# ---- CosineAnnealingWarmupRestarts setup ----\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/solid_eeg/lib/python3.10/site-packages/torch/nn/modules/module.py:1371\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/solid_eeg/lib/python3.10/site-packages/torch/nn/modules/module.py:930\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 930\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    934\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    935\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    941\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/solid_eeg/lib/python3.10/site-packages/torch/nn/modules/module.py:930\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 930\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    934\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    935\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    941\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/solid_eeg/lib/python3.10/site-packages/torch/nn/modules/module.py:930\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 930\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    934\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    935\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    941\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/solid_eeg/lib/python3.10/site-packages/torch/nn/modules/module.py:957\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 957\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    958\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_subclasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeTensor\n",
      "File \u001b[0;32m~/.conda/envs/solid_eeg/lib/python3.10/site-packages/torch/nn/modules/module.py:1357\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1351\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1352\u001b[0m             device,\n\u001b[1;32m   1353\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1354\u001b[0m             non_blocking,\n\u001b[1;32m   1355\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1356\u001b[0m         )\n\u001b[0;32m-> 1357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1363\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 5.81 MiB is free. Including non-PyTorch memory, this process has 1.42 GiB memory in use. Process 2236692 has 37.94 GiB memory in use. Of the allocated memory 922.02 MiB is allocated by PyTorch, and 19.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 6) Build model + diffusion + optimizer\n",
    "# ============================================================\n",
    "IN_CHANNELS = 200 + 2 + 200 + 1   # target(noised) + lat/lon + 9 past grids + 9 past masks = 21\n",
    "unet = UNet(base_dim=128, dim_mults=(1,2,4), in_channels=IN_CHANNELS, image_size=(H,W)).to(DEVICE)\n",
    "diffusion = GaussianDiffusion(unet, image_size=(H,W), time_steps=TIME_STEPS, loss_type='l2').to(DEVICE)\n",
    "\n",
    "# ---- CosineAnnealingWarmupRestarts setup ----\n",
    "\n",
    "\n",
    "max_lr = 4e-4\n",
    "min_lr = 8e-6\n",
    "TOTAL_ITERS = TOTAL_STEPS          # keep these tied\n",
    "warmup_steps = max(1, int(0.1 * TOTAL_ITERS))\n",
    "weight_decay = 1e-4\n",
    "\n",
    "opt = AdamW(diffusion.parameters(), lr=max_lr, betas=(0.9, 0.999), weight_decay=weight_decay)\n",
    "\n",
    "sched = CosineAnnealingWarmupRestarts(\n",
    "    optimizer=opt,\n",
    "    first_cycle_steps=TOTAL_ITERS,  # single full-length cosine cycle\n",
    "    max_lr=max_lr,\n",
    "    min_lr=min_lr,\n",
    "    warmup_steps=warmup_steps,\n",
    "    gamma=1.0                       # no decay across cycles since we use one cycle\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 7) Utilities: invert tanh->raw and metrics\n",
    "# ============================================================\n",
    "def inv_tanh_to_raw(x_tanh, mean, std):\n",
    "    z = torch.atanh(x_tanh.clamp(-0.999, 0.999))\n",
    "    return z * std + mean\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_rmse(diffusion, loader): # add mini batch to check fast\n",
    "    mse_sum_raw = 0.0; w_sum = 0.0\n",
    "    mse_sum_norm = 0.0\n",
    "    for x0_te, m_te, c_te, mu_te, std_te in loader:\n",
    "        x0_te  = x0_te.to(DEVICE)   # tanh(z)\n",
    "        m_te   = m_te.to(DEVICE)\n",
    "        c_te   = c_te.to(DEVICE)\n",
    "        mu_te  = mu_te.to(DEVICE)[:,None,None,None]\n",
    "        std_te = std_te.to(DEVICE)[:,None,None,None]\n",
    "\n",
    "        xhat = diffusion.sample(c_te, clip=False)             # tanh(z)\n",
    "        # raw µg/m³\n",
    "        raw_hat = inv_tanh_to_raw(xhat,  mu_te, std_te)\n",
    "        raw_gt  = inv_tanh_to_raw(x0_te, mu_te, std_te)\n",
    "\n",
    "        mse_sum_raw  += ((raw_hat - raw_gt)**2 * m_te).sum().item()\n",
    "        w_sum        += m_te.sum().item()\n",
    "        # normalized (z) space RMSE (mask)\n",
    "        zhat = torch.atanh(xhat.clamp(-0.999, 0.999))\n",
    "        zgt  = torch.atanh(x0_te.clamp(-0.999, 0.999))\n",
    "        mse_sum_norm += ((zhat - zgt)**2 * m_te).sum().item()\n",
    "\n",
    "    rmse_raw  = math.sqrt(mse_sum_raw / max(w_sum, 1e-8))\n",
    "    rmse_norm = math.sqrt(mse_sum_norm / max(w_sum, 1e-8))\n",
    "    return rmse_raw, rmse_norm, int(w_sum)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_rmse_minibatch(diffusion, loader, max_batches=None): # add mini batch to check fast\n",
    "    mse_sum_raw = 0.0; w_sum = 0.0\n",
    "    mse_sum_norm = 0.0\n",
    "    for i, batch in enumerate(loader):\n",
    "        if (max_batches is not None) and (i >= max_batches):\n",
    "            break\n",
    "        x0_te, m_te, c_te, mu_te, std_te = batch\n",
    "    # for x0_te, m_te, c_te, mu_te, std_te in loader:\n",
    "        x0_te  = x0_te.to(DEVICE)   # tanh(z)\n",
    "        m_te   = m_te.to(DEVICE)\n",
    "        c_te   = c_te.to(DEVICE)\n",
    "        mu_te  = mu_te.to(DEVICE)[:,None,None,None]\n",
    "        std_te = std_te.to(DEVICE)[:,None,None,None]\n",
    "\n",
    "        xhat = diffusion.sample(c_te, clip=False)             # tanh(z)\n",
    "        # raw µg/m³\n",
    "        raw_hat = inv_tanh_to_raw(xhat,  mu_te, std_te)\n",
    "        raw_gt  = inv_tanh_to_raw(x0_te, mu_te, std_te)\n",
    "\n",
    "        mse_sum_raw  += ((raw_hat - raw_gt)**2 * m_te).sum().item()\n",
    "        w_sum        += m_te.sum().item()\n",
    "        # normalized (z) space RMSE (mask)\n",
    "        zhat = torch.atanh(xhat.clamp(-0.999, 0.999))\n",
    "        zgt  = torch.atanh(x0_te.clamp(-0.999, 0.999))\n",
    "        mse_sum_norm += ((zhat - zgt)**2 * m_te).sum().item()\n",
    "\n",
    "    rmse_raw  = math.sqrt(mse_sum_raw / max(w_sum, 1e-8))\n",
    "    rmse_norm = math.sqrt(mse_sum_norm / max(w_sum, 1e-8))\n",
    "    return rmse_raw, rmse_norm, int(w_sum)\n",
    "\n",
    "import math\n",
    "\n",
    "@torch.no_grad()\n",
    "def _crps_from_ensemble(y_flat, samples_flat):\n",
    "    \"\"\"\n",
    "    y_flat:        (N,) ground-truth vector (masked entries only later)\n",
    "    samples_flat:  (K,N) ensemble samples\n",
    "    returns:       (N,) CRPS per entry\n",
    "    \"\"\"\n",
    "    K = samples_flat.shape[0]\n",
    "    # term1 = E|X - y|  ≈ (1/K) Σ_i |x_i - y|\n",
    "    term1 = (samples_flat - y_flat.unsqueeze(0)).abs().mean(dim=0)  # (N,)\n",
    "    # term2 = 0.5 * E|X - X'| ≈ 0.5 * (1/K^2) Σ_ij |x_i - x_j|\n",
    "    diffs = samples_flat.unsqueeze(0) - samples_flat.unsqueeze(1)   # (K,K,N)\n",
    "    term2 = 0.5 * diffs.abs().mean(dim=(0,1))                      # (N,)\n",
    "    return term1 - term2                                            # (N,)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_crps_and_points(diffusion, loader, K=10, clip=False):\n",
    "    \"\"\"\n",
    "    Returns masked dataset-averaged:\n",
    "      CRPS_raw, CRPS_norm, MAE_raw, RMSE_raw, MAE_norm, RMSE_norm, n_obs_bins\n",
    "    \"\"\"\n",
    "    crps_raw_sum = 0.0\n",
    "    crps_norm_sum = 0.0\n",
    "    mae_raw_sum = 0.0\n",
    "    rmse_raw_sum = 0.0\n",
    "    mae_norm_sum = 0.0\n",
    "    rmse_norm_sum = 0.0\n",
    "    w_sum = 0.0\n",
    "\n",
    "    for x0_te, m_te, c_te, mu_te, std_te in loader:\n",
    "        x0_te  = x0_te.to(DEVICE)          # (B,1,H,W), tanh(z)\n",
    "        m_te   = m_te.to(DEVICE)           # (B,1,H,W) mask\n",
    "        c_te   = c_te.to(DEVICE)           # (B,20,H,W)\n",
    "        mu_te  = mu_te.to(DEVICE)[:,None,None,None]\n",
    "        std_te = std_te.to(DEVICE)[:,None,None,None]\n",
    "\n",
    "        B, _, H, W = x0_te.shape\n",
    "        N = B*H*W\n",
    "        mask_flat = m_te.view(N).bool()\n",
    "\n",
    "        # K samples\n",
    "        samples = []\n",
    "        for _ in range(K):\n",
    "            xhat = diffusion.sample(c_te, clip=clip)             # (B,1,H,W) tanh(z)\n",
    "            samples.append(xhat)\n",
    "        S = torch.stack(samples, dim=0)                          # (K,B,1,H,W)\n",
    "\n",
    "        # normalized (z)\n",
    "        z_gt  = torch.atanh(x0_te.clamp(-0.999, 0.999))          # (B,1,H,W)\n",
    "        z_smp = torch.atanh(S.clamp(-0.999, 0.999))              # (K,B,1,H,W)\n",
    "\n",
    "        # raw μg/m³\n",
    "        raw_gt  = z_gt * std_te + mu_te                          # (B,1,H,W)\n",
    "        raw_smp = z_smp * std_te + mu_te                         # (K,B,1,H,W)\n",
    "\n",
    "        # flatten\n",
    "        z_gt_f   = z_gt.view(N)\n",
    "        raw_gt_f = raw_gt.view(N)\n",
    "        z_smp_f  = z_smp.view(K, N)\n",
    "        raw_smp_f= raw_smp.view(K, N)\n",
    "\n",
    "        # CRPS (masked mean)\n",
    "        crps_norm = _crps_from_ensemble(z_gt_f,   z_smp_f)[mask_flat].mean()\n",
    "        crps_raw  = _crps_from_ensemble(raw_gt_f, raw_smp_f)[mask_flat].mean()\n",
    "        crps_norm_sum += crps_norm.item() * mask_flat.sum().item()\n",
    "        crps_raw_sum  += crps_raw.item()  * mask_flat.sum().item()\n",
    "\n",
    "        # point forecast = ensemble mean\n",
    "        z_mean   = z_smp.mean(dim=0).view(N)\n",
    "        raw_mean = raw_smp.mean(dim=0).view(N)\n",
    "\n",
    "        # MAE/RMSE (masked)\n",
    "        mae_norm_sum  += (z_mean - z_gt_f).abs()[mask_flat].sum().item()\n",
    "        rmse_norm_sum += ((z_mean - z_gt_f)**2)[mask_flat].sum().item()\n",
    "        mae_raw_sum   += (raw_mean - raw_gt_f).abs()[mask_flat].sum().item()\n",
    "        rmse_raw_sum  += ((raw_mean - raw_gt_f)**2)[mask_flat].sum().item()\n",
    "\n",
    "        w_sum += mask_flat.sum().item()\n",
    "\n",
    "    CRPS_raw  = crps_raw_sum  / max(w_sum, 1e-8)\n",
    "    CRPS_norm = crps_norm_sum / max(w_sum, 1e-8)\n",
    "    MAE_raw   = mae_raw_sum   / max(w_sum, 1e-8)\n",
    "    MAE_norm  = mae_norm_sum  / max(w_sum, 1e-8)\n",
    "    RMSE_raw  = math.sqrt(rmse_raw_sum  / max(w_sum, 1e-8))\n",
    "    RMSE_norm = math.sqrt(rmse_norm_sum / max(w_sum, 1e-8))\n",
    "\n",
    "    return dict(\n",
    "        CRPS_raw=CRPS_raw, CRPS_norm=CRPS_norm,\n",
    "        MAE_raw=MAE_raw, RMSE_raw=RMSE_raw,\n",
    "        MAE_norm=MAE_norm, RMSE_norm=RMSE_norm,\n",
    "        K=K, n_obs_bins=int(w_sum),\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8) Training loop with periodic eval + checkpoint\n",
    "# ============================================================\n",
    "best_rmse = float('inf')\n",
    "ckpt = os.path.join(RESULT_DIR, 'best_ctx9.pt')\n",
    "\n",
    "pbar = tqdm(range(TOTAL_STEPS), desc=\"Train(ctx9)\")\n",
    "run_loss = 0.0\n",
    "it = iter(train_loader)\n",
    "\n",
    "for step in pbar:\n",
    "    try:\n",
    "        x0, msk, cond, mu, std = next(it)\n",
    "    except StopIteration:\n",
    "        it = iter(train_loader)\n",
    "        x0, msk, cond, mu, std = next(it)\n",
    "\n",
    "    x0   = x0.to(DEVICE, non_blocking=True)\n",
    "    msk  = msk.to(DEVICE, non_blocking=True)\n",
    "    cond = cond.to(DEVICE, non_blocking=True)\n",
    "\n",
    "    opt.zero_grad(set_to_none=True)\n",
    "    loss = diffusion(x0, msk, cond)\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(diffusion.parameters(), 1.0)\n",
    "    opt.step()\n",
    "    sched.step()\n",
    "\n",
    "    run_loss += loss.item()\n",
    "    if (step+1) % LOG_EVERY == 0:\n",
    "        avg = run_loss / LOG_EVERY\n",
    "        run_loss = 0.0\n",
    "        # grab LR robustly\n",
    "        curr_lr = opt.param_groups[0][\"lr\"]\n",
    "        pbar.set_postfix(loss=f\"{avg:.4f}\", lr=f\"{curr_lr:.2e}\")\n",
    "\n",
    "\n",
    "    if (step+1) % EVAL_EVERY == 0:\n",
    "        diffusion.eval()\n",
    "        with torch.inference_mode():\n",
    "            # rmse_raw, rmse_norm, nobs = eval_rmse(diffusion, test_loader) # FIXME : original eval code\n",
    "            rmse_raw, rmse_norm, nobs = eval_rmse_minibatch(diffusion, test_loader, max_batches=2)\n",
    "            # m = eval_crps_and_points(diffusion, test_loader, K=10, clip=False)  # <-- CRPS (and friends)\n",
    "        # print(f\"\\n[Step {step+1}] Test RMSE_raw={rmse_raw:.3f} µg/m³ | RMSE_norm={rmse_norm:.3f} (over {nobs} bins)\")\n",
    "        print(f\"\\n[Step {step+1}] Test RMSE_raw={rmse_raw:.3f} µV (over {nobs} bins)\")\n",
    "        \n",
    "        # print(f\"\\n[Step {step+1}] Test RMSE_raw={rmse_raw:.3f} µg/m³ | RMSE_norm={rmse_norm:.3f} \"\n",
    "        #       f\"(over {nobs} bins) | CRPS_raw={m['CRPS_raw']:.3f} µg/m³ (K={m['K']})\")\n",
    "        if rmse_raw < best_rmse:\n",
    "            best_rmse = rmse_raw\n",
    "            torch.save({'unet': unet.state_dict(),\n",
    "                        'diff': diffusion.state_dict(),\n",
    "                        'H': H, 'W': W}, ckpt)\n",
    "            print(f\"  >> Saved best checkpoint @ {ckpt} (RMSE_raw={best_rmse:.3f})\")\n",
    "        diffusion.train()\n",
    "\n",
    "    if (step+1) % SAVE_SAMPLES_EVERY == 0:\n",
    "        diffusion.eval()\n",
    "        with torch.inference_mode():\n",
    "            # grab a test batch, sample, and save plain grids (tanh -> [0,1] for viewing)\n",
    "            xb, mb, cb, mub, stdb = next(iter(test_loader))\n",
    "            xhat = diffusion.sample(cb.to(DEVICE)).cpu()\n",
    "            vis = (xhat + 1.0) * 0.5\n",
    "            save_image(vis, os.path.join(RESULT_DIR, f\"samples_step{step+1}.png\"), nrow=4)\n",
    "        diffusion.train()\n",
    "\n",
    "print(\"Done. Best Test RMSE_raw:\", best_rmse)\n",
    "\n",
    "# ============================================================\n",
    "# 9) Inference + overlay: GT vs Pred (only observed bins)\n",
    "# ============================================================\n",
    "def overlay_panel(test_loader, model, save_path=os.path.join(RESULT_DIR, 'ctx9_overlay.png'),\n",
    "                  back_img='./airdelhi_background.png'):\n",
    "    try:\n",
    "        back = plt.imread(back_img)\n",
    "    except:\n",
    "        back = None\n",
    "\n",
    "    import matplotlib.colors as colors\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "    cmap0 = LinearSegmentedColormap.from_list('', ['white', 'orange', 'red'])\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        xb, mb, cb, mub, stdb = next(iter(test_loader))\n",
    "        xhat = model.sample(cb.to(DEVICE), clip=False).cpu()  # tanh(z)\n",
    "        raw_hat = inv_tanh_to_raw(xhat, mub[:,None,None,None], stdb[:,None,None,None]).squeeze(1)\n",
    "        raw_gt  = inv_tanh_to_raw(xb,   mub[:,None,None,None], stdb[:,None,None,None]).squeeze(1)\n",
    "        mb      = mb.squeeze(1)\n",
    "\n",
    "    vmax = float(mub.mean() + 3*stdb.mean())\n",
    "    lon_edges = np.linspace(0,1,W+1); lat_edges = np.linspace(0,1,H+1)\n",
    "\n",
    "    B = min(8, raw_hat.size(0))\n",
    "    fig, axes = plt.subplots(2, B, figsize=(3.4*B, 6.8))\n",
    "    for i in range(B):\n",
    "        for row, arr in enumerate([raw_gt[i].numpy(), raw_hat[i].numpy()]):\n",
    "            ax = axes[row, i]\n",
    "            if back is not None: ax.imshow(back, extent=[0,1,0,1], alpha=0.6)\n",
    "            arr_plot = arr.copy()\n",
    "            arr_plot[mb[i].numpy() == 0] = np.nan  # show only observed bins\n",
    "            pm = ax.pcolormesh(lon_edges, lat_edges, arr_plot, cmap=cmap0,\n",
    "                               norm=colors.Normalize(vmin=0, vmax=vmax))\n",
    "            # draw grid\n",
    "            for y in lat_edges: ax.plot([0,1],[y,y], c='k', lw=0.1)\n",
    "            for x in lon_edges: ax.plot([x,x],[0,1], c='k', lw=0.1)\n",
    "            ax.set_axis_off()\n",
    "        axes[0, i].set_title(\"GT (obs bins)\", fontsize=11)\n",
    "        axes[1, i].set_title(\"Pred (obs bins)\", fontsize=11)\n",
    "\n",
    "    cbar = fig.colorbar(pm, ax=axes.ravel().tolist(), fraction=0.03, pad=0.02)\n",
    "    cbar.ax.tick_params(labelsize=10)\n",
    "    plt.tight_layout(); plt.savefig(save_path, dpi=140, bbox_inches='tight'); plt.close(fig)\n",
    "    print(\"Saved overlays to:\", save_path)\n",
    "\n",
    "# ---- Run an overlay on current (or best-loaded) model ----\n",
    "overlay_panel(test_loader, diffusion)\n",
    "\n",
    "# ============================================================\n",
    "# 10) Load best checkpoint & run full test-day eval again\n",
    "# ============================================================\n",
    "def load_and_eval(ckpt_path, test_loader):\n",
    "    ck = torch.load(ckpt_path, map_location=DEVICE)\n",
    "    unet = UNet(base_dim=128, dim_mults=(1,2,4), in_channels=IN_CHANNELS, image_size=(H,W)).to(DEVICE)\n",
    "    unet.load_state_dict(ck['unet'])\n",
    "    diff = GaussianDiffusion(unet, image_size=(H,W), time_steps=TIME_STEPS, loss_type='l2').to(DEVICE)\n",
    "    diff.load_state_dict(ck['diff'])\n",
    "    diff.eval()\n",
    "\n",
    "    # rmse_raw, rmse_norm, nobs = eval_rmse(diff, test_loader) # FIXME : original eval code\n",
    "    rmse_raw, rmse_norm, nobs = eval_rmse_minibatch(diff, test_loader, max_batches=2)\n",
    "    # print(f\"[BEST] Test RMSE_raw={rmse_raw:.3f} µg/m³ | RMSE_norm={rmse_norm:.3f} (over {nobs} bins)\")\n",
    "    print(f\"[BEST] Test RMSE_raw={rmse_raw:.3f} µV (over {nobs} bins)\")\n",
    "    overlay_panel(test_loader, diff, save_path=os.path.join(RESULT_DIR, 'ctx9_overlay_best.png'))\n",
    "    return diff\n",
    "\n",
    "# Example (after training): \n",
    "diff_best = load_and_eval(ckpt,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fb5d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGToGrid(Dataset):\n",
    "    def __init__(self, base_dataset,):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.mean = float(self.base_dataset.mean)\n",
    "        self.std = float(self.base_dataset.std)\n",
    "\n",
    "    def TorchEEG_Grid(self, channel_list, grid_templete=TORCHEEG_2DGRID, H=11, W=11):\n",
    "        \"\"\"\n",
    "        2D Grid based on TorchEEG 2D Grid\n",
    "        input 10-10 coord channel name index \n",
    "        output is grid of channel input\n",
    "        \"\"\"\n",
    "        grid = torch.zeros(H, W, dtype=torch.float32)\n",
    "        mask = torch.zeros(H, W, dtype=torch.float32)\n",
    "        return grid, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        i,o,im,om = self.base[idx]\n",
    "\n",
    "        target_grid = None\n",
    "        target_mask = None\n",
    "        cond = None\n",
    "\n",
    "        return target_grid, target_mask, cond, self.mean, self.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200d6917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some future argparse\n",
    "\n",
    "# TUEG_1.0 path in lucy's pscratch\n",
    "# /pscratch/sd/a/ahhyun/EcoGFound/DATA/scaling_data_V2_Sep_2025/striped_EEG_lmdb/TUEG_1.0/1.0_TUEG/all_resample-500_highpass-0.3_lowpass-None.lmdb\n",
    "LMDB_DIR = \"/pscratch/sd/a/ahhyun/EcoGFound/DATA/scaling_data_V2_Sep_2025/striped_EEG_lmdb/TUEG_1.0/1.0_TUEG/all_resample-500_highpass-0.3_lowpass-None.lmdb\"\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c798205",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Physio_for_SOLID_from_lmdb.__init__() got an unexpected keyword argument 'maxFolds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Set Train and Test dataset and dataloader\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m train_eeg \u001b[38;5;241m=\u001b[39m \u001b[43mPhysio_for_SOLID_from_lmdb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlmdb_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLMDB_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mmaxFolds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m41\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m test_eeg \u001b[38;5;241m=\u001b[39m Physio_for_SOLID_from_lmdb(lmdb_dir\u001b[38;5;241m=\u001b[39mLMDB_DIR,\n\u001b[1;32m      8\u001b[0m                          maxFolds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m      9\u001b[0m                          seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m41\u001b[39m,\n\u001b[1;32m     10\u001b[0m                          train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m                          )\n\u001b[1;32m     13\u001b[0m train_set \u001b[38;5;241m=\u001b[39m EEGToGrid(train_eeg)\n",
      "\u001b[0;31mTypeError\u001b[0m: Physio_for_SOLID_from_lmdb.__init__() got an unexpected keyword argument 'maxFolds'"
     ]
    }
   ],
   "source": [
    "# Set Train and Test dataset and dataloader\n",
    "\n",
    "train_eeg = Physio_for_SOLID_from_lmdb(lmdb_dir=LMDB_DIR,\n",
    "                         maxFolds=5,\n",
    "                         seed=41,\n",
    "                         train=True,)\n",
    "test_eeg = Physio_for_SOLID_from_lmdb(lmdb_dir=LMDB_DIR,\n",
    "                         maxFolds=5,\n",
    "                         seed=41,\n",
    "                         train=False,\n",
    "                         )\n",
    "\n",
    "train_set = EEGToGrid(train_eeg)\n",
    "test_set = EEGToGrid(test_eeg)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_worker=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, num_worker=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661584b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2c0642",
   "metadata": {},
   "outputs": [],
   "source": [
    "LMDB_DIR = \"/pscratch/sd/t/tylee/Dataset/1109_Physio_500Hz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de179f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_from_lmdb(Dataset):\n",
    "    def __init__(self, data_dir, transform, return_info):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.return_info = return_info\n",
    "\n",
    "    def lmdb_to_data(self, idx):\n",
    "        self.db = lmdb.open(self.data_dir, readonly=True, lock=False, readahead=True, meminit=False)\n",
    "        key = self.keys[idx]\n",
    "        with self.db.begin(write=False) as txn:\n",
    "            pair = pickle.loads(txn.get(key.encode()))\n",
    "        data = pair['sample']\n",
    "        label = pair['label']\n",
    "        data_info = pair.get('data_info', {})\n",
    "        \n",
    "        data = to_tensor(data)\n",
    "        if self.transform is not None:\n",
    "            data = self.transform(data)\n",
    "        if self.return_info:\n",
    "            return data/100, label, data_info\n",
    "        else:\n",
    "            return data/100, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_, target_ = self.data[idx], self.target[idx]\n",
    "        in_ = torch.from_numpy(input_.astype(np.float32))\n",
    "        out_ = torch.from_numpy(target_.astype(np.float32))\n",
    "        # print(in_)\n",
    "        \n",
    "        # Normalize pm2.5 values\n",
    "        in_[..., 0] = self.normalize_z(in_[..., 0])\n",
    "        out_[..., 0] = self.normalize_z(out_[..., 0])\n",
    "        \n",
    "        in_[..., 1] = in_[..., 1] / 1440\n",
    "        out_[..., 1] = out_[..., 1] / 1440\n",
    "        \n",
    "        timegap = out_[..., 1:2][0] # get the gap between t+1 and t (ignoring t-1, and t-2)\n",
    "        \n",
    "        in_ = torch.cat([in_[..., 0:1], in_[..., 2:], in_[..., 1:2], ], dim=-1)\n",
    "        out_ = torch.cat([out_[..., 0:1], out_[..., 2:], out_[..., 1:2], ], dim=-1)\n",
    "        \n",
    "        in_[..., 1] = self.normalize(in_[..., 1], self.latmin, self.latmax)\n",
    "        out_[..., 1] = self.normalize(out_[..., 1], self.latmin, self.latmax)\n",
    "        in_[..., 2] = self.normalize(in_[..., 2], self.longmin, self.longmax)\n",
    "        out_[..., 2] = self.normalize(out_[..., 2], self.longmin, self.longmax)\n",
    "        \n",
    "        i = in_[..., 0:1]\n",
    "        im = in_[..., 1:]\n",
    "        o = out_[..., 0:1]\n",
    "        om = out_[..., 1:]\n",
    "        \n",
    "        return i, o, im, om"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c5fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing torch.dataset\n",
    "\n",
    "def xform_day(day):\n",
    "    arr = [0, 30, 61]\n",
    "    w = 0 if day <= 30 else 1 if day <= 61 else 2\n",
    "    mon = ['2020-11-', '2020-12-', '2021-01-'][w]\n",
    "    date = mon + '{:02d}'.format(day - arr[w])\n",
    "    return date\n",
    "\n",
    "\n",
    "def get_suffixes(mode):\n",
    "    suffixes = []\n",
    "    if 'C' in mode or 'A' in mode:\n",
    "        suffixes.append('train')\n",
    "    if 'D' in mode or 'B' in mode:\n",
    "        suffixes.append('test')\n",
    "    return suffixes\n",
    "\n",
    "def rename_cols(data):\n",
    "    data.rename(\n",
    "        columns={'dateTime': 'time', 'lat': 'latitude', 'long': 'longitude', 'pm2_5': 'PM25_Concentration',\n",
    "                 'pm10': 'PM10_Concentration'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "def torch1dgrid(num, bot=0, top=1):\n",
    "    arr = torch.linspace(bot, top, steps=num)\n",
    "    mesh = torch.stack([arr], dim=1)\n",
    "    return mesh.squeeze(-1)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from einops import rearrange        \n",
    "class Delhi(Dataset):\n",
    "    def __init__(\n",
    "        self, mode_t, mode_p, canada, train_days, \n",
    "        maxFolds = 5, target_fold = 0, temporal_scaling=1, spatiotemporal=1, data_dir='/pscratch/sd/d/dpark1/AirDelhi/delhi/processed', \n",
    "        seed=10, nTrainStartDay = 15, nTestStartDay = 75, nTotalDays = 91, train=True):\n",
    "        \n",
    "        self.mode_t = mode_t\n",
    "        self.mode_p = mode_p\n",
    "        self.train_days = train_days\n",
    "        self.train = train\n",
    "        self.maxFolds = maxFolds\n",
    "        self.target_fold = target_fold\n",
    "        self.temporal_scaling = temporal_scaling\n",
    "        self.spatiotemporal = spatiotemporal\n",
    "        self.data_dir = data_dir\n",
    "        self.nTestStartDay = nTestStartDay\n",
    "        self.nTrainStartDay = nTrainStartDay\n",
    "        self.nTotalDays = nTotalDays\n",
    "        \n",
    "        np.random.seed(seed)        \n",
    "        \n",
    "        self.train_suffix = get_suffixes(mode_t)\n",
    "                \n",
    "        if spatiotemporal < 0 and mode_t == 'AB' and mode_p == 'CD':\n",
    "            # Forecasting, single fold is enough\n",
    "            maxFolds = 1\n",
    "    \n",
    "        self.folds = [i for i in range(maxFolds)]\n",
    "        \n",
    "        self.data, self.target = self.proc_custom(target_fold)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_normalize_params(self, target):\n",
    "        all_signal = []\n",
    "        for a in target:\n",
    "            all_signal += list(a[..., 0])\n",
    "        self.mean, self.std = np.array(all_signal).mean(), np.array(all_signal).std()\n",
    "    \n",
    "    def get_spatial_norm_parameters(self, arr_of_days):\n",
    "        \"\"\"\"minmax normalization\"\"\"\n",
    "        latmin = 10e10\n",
    "        latmax = -10e10\n",
    "        longmin = 10e10\n",
    "        longmax = -10e10\n",
    "        for arr in arr_of_days:\n",
    "            minned = arr.min(0)\n",
    "            # print(minned[0])\n",
    "            if minned[2] < latmin:\n",
    "                latmin = minned[2]\n",
    "            if minned[3] < longmin:\n",
    "                longmin = minned[3]\n",
    "                \n",
    "            maxed = arr.max(0)\n",
    "            # print(maxed)\n",
    "            if maxed[2] > latmax:\n",
    "                latmax = maxed[2]\n",
    "            if maxed[3] > longmax:\n",
    "                longmax = maxed[3]\n",
    "        self.latmin, self.latmax, self.longmin, self.longmax =latmin, latmax, longmin, longmax\n",
    "    \n",
    "    def make_data_by_time(self, arr_of_days, t_in = 9, reverse=False, day = 0):\n",
    "        seg_by_time = []\n",
    "        uniq_times = np.unique(arr_of_days[..., 1])\n",
    "        \n",
    "        for t in uniq_times:\n",
    "            idx_ = arr_of_days[..., 1] == t\n",
    "            seg_by_time.append(arr_of_days[idx_])\n",
    "        \n",
    "        in_ = []\n",
    "        out_ = []\n",
    "        for i in range(len(seg_by_time) - t_in):\n",
    "            temp_in = []\n",
    "            for t_ in range(t_in):\n",
    "                temp_in.append(seg_by_time[i + t_])\n",
    "            \n",
    "            # normalize time to relative scale by the last one of the encoder\n",
    "            in_cand = np.copy(np.concatenate(temp_in, axis=0))\n",
    "            out_cand = np.copy(seg_by_time[i + t_in])\n",
    "            \n",
    "            last_enc_t = in_cand[..., 1][-1]\n",
    "            in_cand[..., 1] -= last_enc_t\n",
    "            out_cand[..., 1] -= last_enc_t\n",
    "            in_.append(in_cand)\n",
    "            out_.append(out_cand)\n",
    "            self.day_record.append(day)\n",
    "            \n",
    "            # reverse it\n",
    "            if reverse:\n",
    "                out_cand = np.copy(seg_by_time[i])\n",
    "                temp_in = temp_in[1:]\n",
    "                temp_in.append(seg_by_time[i + t_in])\n",
    "                in_cand = np.copy(np.concatenate(temp_in, axis=0))\n",
    "                last_enc_t = in_cand[..., 1][0]\n",
    "                in_cand[..., 1] -= last_enc_t\n",
    "                out_cand[..., 1] -= last_enc_t\n",
    "                \n",
    "                in_.append(in_cand)\n",
    "                out_.append(out_cand)\n",
    "                self.day_record.append(day)\n",
    "        \n",
    "        \n",
    "        return in_, out_\n",
    "    \n",
    "    def proc_custom(self, fold):\n",
    "        \n",
    "        self.day_record = []\n",
    "        \n",
    "        train_data = {'input':[], 'target':[]}\n",
    "        test_data = {'input':[], 'target':[]}\n",
    "        \n",
    "        for day in range(self.nTrainStartDay, self.nTestStartDay):\n",
    "            date = []\n",
    "            for i in range(self.train_days,-1,-1):\n",
    "                date.append(xform_day(day-i))\n",
    "\n",
    "            train_input,train_output,test_input,test_output = self.process_np(fold, date)\n",
    "            train_in = np.concatenate([train_output[..., np.newaxis], train_input], axis=1) # 1 days\n",
    "            train_out = np.concatenate([test_output[..., np.newaxis], test_input], axis=1) # 1 day\n",
    "            \n",
    "            seg_in, seg_out = self.make_data_by_time(train_in, day = day)\n",
    "            \n",
    "            train_data['input'] += seg_in\n",
    "            train_data['target'] += seg_out            \n",
    "        \n",
    "        \n",
    "        \n",
    "        seg_in, seg_out = self.make_data_by_time(train_out)\n",
    "        train_data['input'] += seg_in\n",
    "        train_data['target'] += seg_out\n",
    "            \n",
    "        \n",
    "        for day in range(self.nTestStartDay, self.nTotalDays+1):\n",
    "            date = []\n",
    "            for i in range(self.train_days,-1,-1):\n",
    "                date.append(xform_day(day-i))\n",
    "\n",
    "            train_input,train_output,test_input,test_output = self.process_np(fold, date)\n",
    "            test_in = np.concatenate([train_output[..., np.newaxis], train_input], axis=1) # 1 days\n",
    "            test_out = np.concatenate([test_output[..., np.newaxis], test_input], axis=1) # 1 day\n",
    "\n",
    "            seg_in, seg_out = self.make_data_by_time(test_in, reverse = False)\n",
    "            \n",
    "            test_data['input'] += seg_in\n",
    "            test_data['target'] += seg_out            \n",
    "            \n",
    "        seg_in, seg_out = self.make_data_by_time(test_out, reverse = False)\n",
    "        test_data['input'] += seg_in\n",
    "        test_data['target'] += seg_out\n",
    "\n",
    "        self.get_normalize_params(train_data['target']) \n",
    "        self.get_spatial_norm_parameters(train_data['target'])\n",
    "            \n",
    "        if self.train:\n",
    "            data = train_data['input']\n",
    "            target = train_data['target']\n",
    "            print(len(data), len(target))\n",
    "            \n",
    "        else:\n",
    "            data = test_data['input']\n",
    "            target = test_data['target']\n",
    "            print(len(data), len(target))\n",
    "\n",
    "        return data, target        \n",
    "    \n",
    "    \n",
    "\n",
    "    def process_np(self, fold, date):\n",
    "        tmStart = datetime.datetime.now()\n",
    "        train_input,train_output,test_input,test_output = self.return_data_time(fold=fold, data=date, with_scaling=True)\n",
    "        return train_input,train_output,test_input,test_output\n",
    "    \n",
    "    def return_data_time(self, fold, data, with_scaling):\n",
    "        train_input = None\n",
    "        if 'A' in self.mode_t or 'B' in self.mode_t:\n",
    "            for idx,dt in enumerate(data[:-1]):\n",
    "                for suffix in self.train_suffix:\n",
    "                    input = pd.read_csv(self.data_dir+'/'+dt+'_f'+str(fold)+'_'+suffix+'.csv')\n",
    "                    # if self.temporal_scaling:\n",
    "                    #     input.dateTime += idx * 24 * 60\n",
    "                    train_input = pd.concat((train_input, input))\n",
    "                    \n",
    "        if 'C' in self.mode_t:\n",
    "            input = pd.read_csv(self.data_dir + '/' + data[-1] + '_f' + str(fold) + '_train.csv')\n",
    "            # if self.temporal_scaling:\n",
    "            #     input.dateTime += (len(data)-1) * 24 * 60\n",
    "            train_input = pd.concat((train_input, input))\n",
    "\n",
    "        test_input = pd.read_csv(self.data_dir+'/'+data[-1]+'_f'+str(fold)+'_test.csv')\n",
    "        \n",
    "        if 'C' in self.mode_p:\n",
    "            input = pd.read_csv(self.data_dir + '/' + data[-1] + '_f' + str(fold) + '_train.csv')\n",
    "            test_input = pd.concat((input, test_input))\n",
    "            \n",
    "        # if self.temporal_scaling:\n",
    "        #     test_input.dateTime += (len(data)-1) * 24 * 60\n",
    "\n",
    "        return self.return_data_0(train_input, test_input, with_scaling)\n",
    "\n",
    "    \n",
    "    def return_data_0(self, train_input, test_input, with_scaling):\n",
    "        train_output = np.array(train_input['pm2_5'])\n",
    "        train_input = train_input[['dateTime','lat','long']]\n",
    "        test_output = np.array(test_input['pm2_5'])\n",
    "        test_input = test_input[['dateTime','lat','long']]\n",
    "\n",
    "        # if with_scaling:\n",
    "        #     scaler = MinMaxScaler().fit(train_input)\n",
    "        #     if self.temporal_scaling:\n",
    "        #         data = scaler.transform(pd.concat((train_input, test_input)))\n",
    "        #         test_input = data[len(train_input):]\n",
    "        #         train_input = data[:len(train_input)]\n",
    "        #     else:\n",
    "        #         train_input = scaler.transform(train_input)\n",
    "        #         test_input = scaler.transform(test_input)\n",
    "        return train_input,train_output,test_input,test_output\n",
    "\n",
    "    def set_target_fold(self, fold=0):\n",
    "        self.fold = fold\n",
    "        print('target fold set to {}'.format(self.fold))\n",
    "        \n",
    "    def normalize_z(self, arr):\n",
    "        return (arr - self.mean) / self.std\n",
    "    \n",
    "    def normalize(self, data, min_, max_):\n",
    "        return (data - min_) / (max_ - min_)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_, target_ = self.data[idx], self.target[idx]\n",
    "        in_ = torch.from_numpy(input_.astype(np.float32))\n",
    "        out_ = torch.from_numpy(target_.astype(np.float32))\n",
    "        # print(in_)\n",
    "        \n",
    "        # Normalize pm2.5 values\n",
    "        in_[..., 0] = self.normalize_z(in_[..., 0])\n",
    "        out_[..., 0] = self.normalize_z(out_[..., 0])\n",
    "        \n",
    "        in_[..., 1] = in_[..., 1] / 1440\n",
    "        out_[..., 1] = out_[..., 1] / 1440\n",
    "        \n",
    "        timegap = out_[..., 1:2][0] # get the gap between t+1 and t (ignoring t-1, and t-2)\n",
    "        \n",
    "        in_ = torch.cat([in_[..., 0:1], in_[..., 2:], in_[..., 1:2], ], dim=-1)\n",
    "        out_ = torch.cat([out_[..., 0:1], out_[..., 2:], out_[..., 1:2], ], dim=-1)\n",
    "        \n",
    "        in_[..., 1] = self.normalize(in_[..., 1], self.latmin, self.latmax)\n",
    "        out_[..., 1] = self.normalize(out_[..., 1], self.latmin, self.latmax)\n",
    "        in_[..., 2] = self.normalize(in_[..., 2], self.longmin, self.longmax)\n",
    "        out_[..., 2] = self.normalize(out_[..., 2], self.longmin, self.longmax)\n",
    "        \n",
    "        i = in_[..., 0:1]\n",
    "        im = in_[..., 1:]\n",
    "        o = out_[..., 0:1]\n",
    "        om = out_[..., 1:]\n",
    "        \n",
    "        return i, o, im, om"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solid_eeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
